{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Walmart](https://4.bp.blogspot.com/-US_5wafsHJI/VAo33JnvTZI/AAAAAAAADS4/k4tXNXvuD9k/s1600/Attention%2BWalmart%2BShoppers.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capstone Presentation\n",
    "Cindy Villanueva | Alberto Puentes | Heather McMillan | Natasha Rivers\n",
    "\n",
    "#### August 19, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:3px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import scipy.stats as stats\n",
    "\n",
    "import math\n",
    "\n",
    "#visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#custom modules\n",
    "import new_wrangle as w\n",
    "import model as m\n",
    "\n",
    "#sklearn preprossing, clustering and modeling libraries\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import RFE, SelectKBest, f_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import mean_squared_error, explained_variance_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Palette Specs for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#color palette for visualizations\n",
    "walmart_palette_c = ['#004c91', '#007dc6', '#78b9e7', '#f47321', '#ffc220', '#367c2b', '#76c043']\n",
    "walmart_palette_d = ['#004c91', '#ffc220' , '#f47321', '#367c2b','#007dc6', '#76c043', '#78b9e7']\n",
    "sns.set_palette(walmart_palette_d)\n",
    "\n",
    "#Set parameters for graphs\n",
    "plt.rc('figure', figsize=(13, 7))\n",
    "# dictionary for font info\n",
    "font = {'size'   : 14}\n",
    "# pass in the font dict as kwargs\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:3px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Don't you wish you could predict the future? With a little bit of data science we can get close. In this notebook our team walks through the full data science pipeline with some Walmart Retail sales data, and attempts to do just that. We acquire, clean, prepare, explore, model and evaluate the data in order to create a model that can predict sales for the next week. We will walk through how we created a linear regression model, using time series data, that was 29% more accurate than merely predicting that sales would be the same as they were the year before.\n",
    "\n",
    "#### Data Intro\n",
    "This data includes weekly sales information from 45 different walmart stores of various sizes (sqft). Indications of important holidays are notated for each week. There is also a CPI (Consumer Price Index), regional fuel price, and unemployment measurement, and regional average temperature for each observation. In addition to the historical data, which we thought would be a good indicator of price year over year, we also formed several hypotheses which we sought to answer over the course of this project.\n",
    "   - Do Unemployment and CPI (inflation) have an effect on weekly sales? If so, would we need to lag them back? \n",
    "   - We think that the higher the CPI number, the lower the sales (because goods get more expensive when inflation goes up)\n",
    "   - If Fuel Prices are higher will the sales nubmers be lower?\n",
    "   - Does forecasted weather impact sales? i.e. next week’s weather, impact on sales. Higher temperatures, effect on sales? Lower temperatures, effect on sales?\n",
    "   \n",
    "#### Why is this important?\n",
    "It's important to have an idea of what is to come in regards to sales for several reasons. For store managers and shareholders, having accurate predictions is beneficial for good inventory management and forecasting demand (impacts it can have on staffing and stocking). And a more efficient cost structure leads to more money going to the bottom line. Also, perhaps more importantly, if managers can accurately predict demand, customers will be more satisfied when they go to the store and see the products they want on the shelves. \n",
    "\n",
    "This type of technology can be adjusted to fit other retail businesses. A different store will have other factors that influence your sales? Economic factors? Interesting holiday spike? Located in a neighborhood with different shopping trends? That information can be captured to help create more accurate forecasts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquire\n",
    "\n",
    "The main table for this data came from [Kaggle](https://www.kaggle.com/aditya6196/retail-analysis-with-walmart-data), and the stores information table came directly from the original [Walmart Competition](https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid blue\"> </hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'walmart_sales.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-41d8ed9cb3e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Import data using acquire_data from new_wrangle.py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#df_data = w.acquire_data()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/codeup-data-science/database-exercises/capstone/new_wrangle.py\u001b[0m in \u001b[0;36macquire_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mwalmart\u001b[0m \u001b[0mstores\u001b[0m \u001b[0mcsv\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msets\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mDate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     '''\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'walmart_sales.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stores.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mjoined_df\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Store'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2008\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'walmart_sales.csv'"
     ]
    }
   ],
   "source": [
    "#Import data using acquire_data from new_wrangle.py\n",
    "df= w.acquire_data()\n",
    "#df_data = w.acquire_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a look at the data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Findings and Takeaways**:\n",
    "* Data sets provided in two .csv files that are merged into one dataframe for the project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:3px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare\n",
    "\n",
    "In this section of the pipeline, we needed to undertake the most difficult task for this project: Transforming time series data into data that is ready for a regression model. We had to capture the time data (numerically), historical sales and economic factor data, as well as the target (next week's sales) in one row. We also split the data into training and testing sets for exploration and modeling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid blue\"> </hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute preparation function from new_wrangle.py\n",
    "df= w.wrangle_walmart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split and Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split and scale data using split_scale function in new_wrangle.py\n",
    "train, test, X_train_scaled, X_test_scaled, y_train, y_test = w.split_scale(df, 'next_week_sales_target', scaler = MinMaxScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a look at new df after preperation was completed\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Findings and Takeaways:\n",
    "* Basic clean consisted of lowercasing features, renaming columns, converting selected dtypes appropriately, rounding decimals and converting date object into datetime \n",
    "* Identified a handful of outliers based on store type and weekly sales data and decided to reclassify store type in accordance with prevailing weekly sales threshold\n",
    "* Feature engineering:\n",
    "    * Added feature labeling holiday by Date: Super Bowl, Labor Day, Thanksgiving and Christmas\n",
    "        * Additional column created with dummy variables for the holidays\n",
    "        * `pre_christmas` feature was created to capture the Christmas holiday sales buildup two weeks prior to the holiday\n",
    "    * Created additional feature containing the following week's 52 week (1yr) weekly sales lookback by shifting up weekly sales by 51 periods\n",
    "    * Created monthly and quarterly rolling window features in each observation for this_week_unemployment, fuel_prices & CPI features\n",
    "        * Additionally, created delta features for all above on a month-over-month and quarter-over-quarter basis\n",
    "            * Each observation had the rolling window averages...look backs of 4 and 12 periods with percent change calculation\n",
    "    * Created new index concating (current Date) + (store number) + (week+1 Date) features\n",
    "    * **Target**: weekly sales shifted back 1 time period to be regressed on observation features from previous week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:3px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore\n",
    "\n",
    "Here we take a look at the different features of our data set, to better understand the relationships between variables and our target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid blue\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#explore our target\n",
    "plt.figure(figsize=(8, 10))\n",
    "sns.histplot(train,\n",
    "                 x=train['next_week_sales_target'],\n",
    "                 #hue='loan_status',\n",
    "                 multiple='layer'\n",
    "                 )\n",
    "plt.title(\"Distribution of Next week sales\")\n",
    "plt.xlabel('Weekly sales in dollars')\n",
    "plt.ylabel('Number of weeks')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ticklabel_format(style = 'plain')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create temp df with a dateteime index for explore\n",
    "df_data= w.acquire_data()\n",
    "df_data1= w.acquire_data()\n",
    "df_data['Date']= pd.to_datetime(df_data['Date'], dayfirst=True)\n",
    "df_data = df_data.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annual weekly sales by month\n",
    "plt.figure(figsize=(16, 10))\n",
    "df_data.Weekly_Sales.groupby([df_data.index.year, df_data.index.month]).sum().unstack(0).plot(figsize = (14,10))\n",
    "plt.title('Annual Weekly Sales by Month', fontsize = 16)\n",
    "plt.ticklabel_format(style='plain', axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Findings & Takeaways:\n",
    "* 2012 appears to contradict the trends seen in the other years\n",
    "    * After digging into the weekly sales, we discovered that this was due to a calendar effect where the end of weeks fell on different points at the end of March or beginning of April\n",
    "        * Note for 2nd iteration, potential normalization \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2)\n",
    "fig.suptitle('Visualizing target vs features', fontsize = 15)\n",
    "fig.tight_layout(h_pad = 2)\n",
    "fig.set_figheight(15)\n",
    "fig.set_figwidth(15)\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "ax[0, 0] = df_data.Weekly_Sales.resample('M').sum().plot()\n",
    "ax[0, 0].set_title('Total Weekly Sales by Month')\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "ax[0, 1]= df_data.Unemployment.resample('M').mean().plot()\n",
    "plt.xticks(rotation=0)\n",
    "ax[0, 1].set_title('Average Unemployment by Month')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "ax[1, 0]= df_data.Fuel_Price.resample('M').mean().plot()\n",
    "ax[1, 0].set_title('Average Fuel Price by Month')\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "ax[1, 1]=  df_data.CPI.resample('M').mean().plot()\n",
    "ax[1, 1].set_title('Average CPI by Month')\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Findings & Takeaways:\n",
    "\n",
    "* Weekly sales spike significantly over the Nov-Dec months only to nosedive to annual lows in January\n",
    "    * A rebound in sales during Feb after cyclical lows in Jan \n",
    "        * Much milder spikes appear consistent in the months of June and August\n",
    "* Avg unemployment shows a clear declining trend whild avg fuel price shows a clear rising trend\n",
    "    * Expectation is that this should influence a rising trend in weekly sales. something to be aware of\n",
    "* Seasonality in both the avg deflated sales and avg temperature occurs over an annual basis\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize store_type by store_size\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.boxplot(x='store_type', y='store_size', data=train)\n",
    "plt.title('Store Type by Size')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Findings & Takeaways:\n",
    "* Store type directly related to size\n",
    "    * Anomalous observations were found in store types A & B appear more in line with store type C\n",
    "        * These were: store 3, store 5, store 33, store 36 \n",
    "        * Instead of dropping, we decided to reclassify these and include them in our type C data\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize target with holidays\n",
    "plt.figure(figsize=(14,6))\n",
    "sns.boxplot(x= train['next_week_holiday_name'], y =train['next_week_sales_target'] )\n",
    "plt.ticklabel_format(style='plain', axis='y')\n",
    "plt.xlabel('\\n Next Week - Holiday', fontsize = 13)\n",
    "plt.ylabel('Next Week Sales', fontsize = 13)\n",
    "plt.title('Sales by Holiday', fontsize = 16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Findings & Takeaways:\n",
    "* Our Pre_Christmas & Thanksgiving sales appear to be strong sales drivers.  \n",
    "    * Further investigation shows Thanksgiving sales are primarily driven by Black Friday specials\n",
    "    * After noticing a run up in sales leading into the Christmas week, we created an additional feature to capture this period\n",
    "        * The exploration above shows our pre_Christmas period being our strongest sales driver within these observations\n",
    "            * The Christmas tag was applied to the week ending after the Christmas holiday negating the holiday impact; unlike the Thanksgiving holiday where Black Friday occurs in the same week\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation with target and all other features\n",
    "wal_corr = train.corr()['next_week_sales_target'].sort_values(ascending=False)\n",
    "#visualize the correlation between features and our target (next week sales)\n",
    "plt.figure(figsize=(8, 12))\n",
    "heatmap = sns.heatmap(train.corr()[['next_week_sales_target']].sort_values(by='next_week_sales_target', ascending=False), vmin=-1, vmax=1, annot=True, cmap='mako_r')\n",
    "heatmap.set_title('Features Correlating with weekly sales', fontdict={'fontsize':18}, pad=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Findings & Takeaways:\n",
    "* Visualizing the correlation between our target and other features allowed us to see:\n",
    "    * Highest correlation between our target and last years sales, this weeks store size, and holiday indicators.    \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data1.head(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column list to look at for pairplot\n",
    "cols = ['Weekly_Sales','Temperature','Fuel_Price','CPI',\n",
    "        'Unemployment','Type','Size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pairplot\n",
    "sns.pairplot(data = df_data[cols], hue = 'Type', corner=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Findings & Takeaways\n",
    "\n",
    "* No trends really jump out right away. Biggest thing, is that when unemployment is higher, sales are lower. Maybe people are out of jobs and they're not shopping. Also it doesn't appear that there was much time where the unemployment *was* high during this time period here. (between 2010 - 2012)\n",
    "* There is some gap in in CPI between 150 and 180 or so. Maybe there was some sort of jump in the market either up or down. \n",
    "* Highest sales for the big stores (in blue), were when the temperature was in the 40s. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up dataframe to use in lag plots\n",
    "# columns we'll need\n",
    "cols = ['next_week_sales_target', 'next_week_holiday_name', 'next_week_date']\n",
    "\n",
    "# create temp dataframe with columns, set to datetime index, sort the index and drop nulls\n",
    "df_data1 = df[cols].set_index('next_week_date').sort_index().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Various Target Lag plots\n",
    "\n",
    "fig, ax = plt.subplots(2, 2)\n",
    "fig.suptitle('Weekly sales vs various lags')\n",
    "fig.tight_layout(h_pad = 2, w_pad = 4)\n",
    "fig.set_figheight(18)\n",
    "fig.set_figwidth(15)\n",
    "\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "ax1 = sns.scatterplot(df_data1.groupby('next_week_date').next_week_sales_target.agg('sum'), \n",
    "                      df_data1.groupby('next_week_date').next_week_sales_target.agg('sum').shift(-1), \n",
    "                      hue=df_data1.next_week_holiday_name)\n",
    "plt.xlabel('$weekly sales$')\n",
    "plt.ylabel('$sales - 1$')\n",
    "ax1.ticklabel_format(style = 'plain')\n",
    "ax1.set_title('Lag plot with lag=1')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "ax2 = sns.scatterplot(df_data1.groupby('next_week_date').next_week_sales_target.agg('sum'), \n",
    "                      df_data1.groupby('next_week_date').next_week_sales_target.agg('sum').shift(-4), \n",
    "                      hue=df_data1.next_week_holiday_name)\n",
    "plt.xlabel('$weekly sales$')\n",
    "plt.ylabel('$sales - 4$')\n",
    "ax2.ticklabel_format(style = 'plain')\n",
    "ax2.set_title('Lag plot with lag=4')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "ax3= sns.scatterplot(df_data1.groupby('next_week_date').next_week_sales_target.agg('sum'), \n",
    "                      df_data1.groupby('next_week_date').next_week_sales_target.agg('sum').shift(-12), \n",
    "                      hue=df_data1.next_week_holiday_name)\n",
    "plt.xlabel('$weekly sales$')\n",
    "plt.ylabel('$sales - 12$')\n",
    "ax3.ticklabel_format(style = 'plain')\n",
    "ax3.set_title('Lag plot with lag=12')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "ax4= sns.scatterplot(df_data1.groupby('next_week_date').next_week_sales_target.agg('sum'), \n",
    "                      df_data1.groupby('next_week_date').next_week_sales_target.agg('sum').shift(-52), \n",
    "                      hue=df_data1.next_week_holiday_name)\n",
    "plt.xlabel('$weekly sales$')\n",
    "plt.ylabel('$sales - 52$')\n",
    "ax4.ticklabel_format(style = 'plain')\n",
    "ax4.set_title('Lag plot with lag=52')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Findings & Takeaways:\n",
    "* There is a clear linear correlation when lagging the data on an annual basis (52 weeks)\n",
    "* There also appears to be significant correlation when lagging one period\n",
    "    * outliers in the one period lag appear evenly distributed across store size groupings and appear to mirror each other suggesting the same time periods may be mirrored\n",
    "        * perhaps these are due to the holiday periods; check to see if any possibility of addressing\n",
    "            * CONFIRMED: the outliers occur in consecutive dates surrounding the Thanksgiving and Christmas holidays.  Specifically, [2010-11-19, 2010-11-26, 2010-12-17, 2010-12-24, 2011-11-18, 2011-11-25, 2011-12-16, 2011-12-23]\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis 1: Pearson's (cont vs cont)\n",
    "$H_0$: There is no correlation between next week sales and this week sales \n",
    "\n",
    "$H_a$: There is a correlation between next week sales and this week sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pearsons correlation on entire train set\n",
    "#number of rows\n",
    "n = train.shape[0] \n",
    "\n",
    "#degrees of freedom- how much the data can vary\n",
    "deg_f = n-2 \n",
    "\n",
    "#confidence interval (!)\n",
    "conf_in = 0.95\n",
    "\n",
    "#calculate alpha\n",
    "alpha = 1- conf_in\n",
    "\n",
    "#identify x and y\n",
    "x= train.next_week_sales_target\n",
    "y= train.this_week_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate r and p values\n",
    "r, p = stats.pearsonr(x,y)\n",
    "r,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'We calculate a pearson r of {r:3f} and a statistical certainty p of {p:4f}')\n",
    "print(f'Because p {p:4f} < α  {alpha:4f}, we can reject our null hypothesis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis 2: Pearson's (cont vs cont)\n",
    "$H_0$: There is no correlation between next week's sales and sales from the same period last year\n",
    "\n",
    "$H_a$: There is a correlation between next week's sales and sales from the same period last year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pearsons correlation on entire train set\n",
    "#number of rows\n",
    "n = train.shape[0] \n",
    "\n",
    "#degrees of freedom- how much the data can vary\n",
    "deg_f = n-2 \n",
    "\n",
    "#confidence interval (!)\n",
    "conf_in = 0.95\n",
    "\n",
    "#calculate alpha\n",
    "alpha = 1- conf_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify x and y\n",
    "x= train.next_week_sales_target\n",
    "y= train.next_week_1_year_ago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate r and p values\n",
    "r, p = stats.pearsonr(x,y)\n",
    "r,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'We calculate a pearson r of {r:3f} and a statistical certainty p of {p:4f}')\n",
    "print(f'Because p {p:4f} < α  {alpha:4f}, we can reject our null hypothesis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis 3: T-Test (discrete vs cont)\n",
    "$H_0$: There is no relationship between this next_weeks_sales_target and pre_christmas\n",
    "\n",
    "$H_a$: There is a relationship between this next_weeks_sales_target and pre_christmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confidence interval (!)\n",
    "conf_in = 0.95\n",
    "\n",
    "#calculate alpha\n",
    "alpha = 1- conf_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check sample size, must be more than 30 to meet assumptions\n",
    "train.next_week_sales_target.shape, train.pre_christmas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check variance\n",
    "train.next_week_sales_target.var(), train.pre_christmas.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 tailed t-test\n",
    "t, p = stats.ttest_ind(train.next_week_sales_target,train.pre_christmas, equal_var=False)\n",
    "t, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'We calculate a t of {t:4f} and a statistical certainty p of {p:4f}')\n",
    "print(f'Because t {t:4f} < α  {alpha:2f}, we can reject our null hypothesis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Findings and Takeaways:\n",
    "* These were all must haves.  \n",
    "    * If weekly sales observations were independent, there would be no common drivers to explore and build a regression model around that would enable us to forecast weekly sales one week in advance.  \n",
    "    * Additionally, establishing statistical significance in the relationship between our target and our pre_christmas feature enables us to model what our exploration clearly defined as our most significant source of seasonality\n",
    "    \n",
    "Given that the p values were all below 0.05, we have a project!\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addressing Collinearity in our Engineered Features\n",
    "\n",
    "Some features that we created (the changes in gas prices and changes in CPI and such) probably were correlated to each other and not just to the target. This will present an issue when going into the modeling phase. We need features to correlate with the target, not with each other. That's called *Multicolinearity* and we deal with it here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Testing for collinearity: engineered unemployment features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.collinearity_unemployment(X_train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Findings & Takeaways: unemployment\n",
    "* `this_week_unemployment` nearly perfectly correlated with rolling avgs; p value under 0.05, recommend dropping unemployment\n",
    "* Rolling averages nearly perfectly correlated with each other; p value under 0.05, recommend dropping `quarterlyrolling`\n",
    "* Deltas correlation co-efficient 0.42. p value under 0.05; is this correlation significant enough to drop?\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Testing for collinearity: engineered fuel price features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.collinearity_fuel(X_train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Findings & Takeaways: fuel price\n",
    "* `fuel_price` nearly perfectly correlated with rolling avgs; p value under 0.05, recommend dropping `fuel_price`\n",
    "* 4wk rolling has a 0.37 corr coefficient vs avgQoQ; p value under 0.05, is this threshold high enough to drop?\n",
    "* Rolling averages strongly correlated with each other; p value under 0.05, recommend dropping quarterly rolling as 4wk captures both quarterly rolling and fuel price well\n",
    "* Deltas correlation co-efficient 0.2; p value under 0.05, recommend keeping both\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Testing for collinearity: engineered CPI features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.collinearity_cpi(X_train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Findings & Takeaways: CPI\n",
    "* `CPI` nearly perfectly correlated with rolling avgs; p value under 0.05, recommend dropping `CPI`\n",
    "* Rolling averages nearly perfectly correlated with each other; p value under 0.05, recommend dropping quarterly rolling\n",
    "* Deltas correlation co-efficient 0.25. p value under 0.05; is this correlation significant enough to drop?\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Iterative Feature Elimination due to Auto Correlation findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features to drop before modeling due to autocorrelation\n",
    "col = ['this_week_unemployment', 'fuel_price', 'CPI', 'unemp_quarterly_rolling', 'fuel_quarterly_rolling', 'cpi_quarterly_rolling']\n",
    "\n",
    "#drop columns that have coliniarity\n",
    "X_train_scaled = X_train_scaled.drop(columns = col)\n",
    "X_test_scaled = X_test_scaled.drop(columns = col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:3px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "In this phase we create a regression model using the following steps.\n",
    "1. Establish a baseline to test our model against\n",
    "2. Create and fit various types of regression models\n",
    "3. Evaluate using Cross validation\n",
    "4. Test the best model on unseen data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid blue\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Notes for Modeling Section:\n",
    "    \n",
    "* **Scaler utilized** = MinMax()\n",
    "\n",
    "* **Baselines**: 1) weekly sales mean & 2) 52 week look back to previous year weekly sales ('next_week_1_year_ago')\n",
    "\n",
    "* **Algorithms utilized:**\n",
    "    - Linear Regression(OLS)\n",
    "    - Lasso Lars\n",
    "    - TweedieRegressor (GLM)\n",
    "    - Polynomial Regression\n",
    "\n",
    "#### For each model we used:\n",
    "\n",
    " - **GridSearchCV**: grid search cross-validation (GridSearchCV) for hyperparameter optimization.\n",
    " \n",
    "- **Feature Engineering:**\n",
    "\n",
    "   - **RFE :** (recursive feature elimination)  recursively removes attributes to meet the required number of features and then builds a model on those attributes that remain.\n",
    "   - **Select KBest:** removes all but the highest scoring features.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model features\n",
    "features = ['store_size', 'this_week_unemployment', 'next_week_1_year_ago', 'this_week_sales', 'pre_christmas']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y_train and Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert y_train y _ validate to df\n",
    "y_train_df = pd.DataFrame( {'actual': y_train})\n",
    "y_test_df = pd.DataFrame( {'actual': y_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 1: mean of weekly sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the baseline using mean of actual weekly sales\n",
    "baseline= y_train_df['actual'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column called baseline to compare\n",
    "y_train_df['baseline'] = baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE for baseline model\n",
    "rmse_baseline_train= math.sqrt(mean_squared_error(y_train_df.actual, y_train_df.baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe to make data easier to visualize/understand\n",
    "metric_df = pd.DataFrame(data=[{\n",
    "    'model': \"Baseline (using mean)\",\n",
    "    'rmse_train': round(rmse_baseline_train, 4),\n",
    "    'r^2': round(explained_variance_score(y_train_df.actual, y_train_df.baseline), 4)\n",
    "\n",
    "}])\n",
    "\n",
    "round(metric_df, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 2 : prior year's weekly sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline using last years sales as predictions\n",
    "y_train_df['last_year_baseline'] = train['next_week_1_year_ago']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE for baseline 2 model\n",
    "rmse_baseline2_train= math.sqrt(mean_squared_error(y_train_df.actual, y_train_df.last_year_baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE Baseline 2\n",
    "round(rmse_baseline2_train, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Baseline 2 to our metric_df\n",
    "metric_df = metric_df.append(\n",
    "    {\n",
    "    'model': \"Baseline (using last year's sales)\",\n",
    "    'rmse_train': round(rmse_baseline2_train, 2),\n",
    "    'r^2': round(explained_variance_score(y_train_df.actual, y_train_df.last_year_baseline),4),\n",
    "    }, ignore_index=True)\n",
    "\n",
    "round((metric_df), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL 1: LinearRegression (OLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Hyperparameter optimization with Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the parameters we wish to use as a dictionary, then use that dictionary when we create the class.\n",
    "params = {'normalize': [ True, False],\n",
    "          'fit_intercept': [True, False]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deploy gridsearch function using \n",
    "round(m.gridsearch(X_train_scaled, y_train_df, LinearRegression() , params, 'neg_root_mean_squared_error'), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Feature Selection using Select K Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at columns in y_train\n",
    "y_train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using my function for SelectkBest\n",
    "top_sb = m.select_kbest(X_train_scaled, y_train, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model and calculate RMSE\n",
    "ols_sb = m.create_model(X_train_scaled[top_sb], y_train_df, 'actual',\\\n",
    "                       LinearRegression(normalize=False,\\\n",
    "                        fit_intercept=True ), 'modelOLS' )\n",
    "round(ols_sb['rmse'], 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "clf = LinearRegression(normalize=True, fit_intercept=True )\n",
    "# cv = number of folds\n",
    "cross_val_score(clf, X_train_scaled[top_sb], y_train, cv=3, scoring = 'neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the ols_sb model metrics to metric_df\n",
    "metric_df = metric_df.append(\n",
    "    {\n",
    "    'model': 'ols_sb',\n",
    "    'rmse_train': ols_sb['rmse'],    \n",
    "    'r^2' : ols_sb['r2']}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Feature Selection using  RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the function to get RFE selected features\n",
    "top_rfe = m.select_rfe(X_train_scaled, y_train, 10,LinearRegression(normalize=True, fit_intercept=True ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model and calculate RMSE\n",
    "ols_rfe = m.create_model(X_train_scaled[top_rfe], y_train_df, 'actual', LinearRegression(normalize=True, fit_intercept=True ), 'modelOLS' )\n",
    "round(ols_rfe['rmse'], 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "clf = LinearRegression(normalize=True, fit_intercept=True )\n",
    "# cv = number of folds\n",
    "cross_val_score(clf, X_train_scaled[top_rfe], y_train, cv=3, scoring = 'neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the ols_rfe model metrics to metric_df\n",
    "metric_df = metric_df.append(\n",
    "    {\n",
    "    'model': 'ols_rfe',\n",
    "    'rmse_train': ols_rfe['rmse'],    \n",
    "    'r^2' : ols_rfe['r2']}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL 2: LassoLars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Hyperparameter optimization with Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the parameters we wish to use as a dictionary, then use that dictionary when we create the class.\n",
    "params = {\n",
    "          'normalize': [True, False],\n",
    "          'fit_intercept':[True, False],\n",
    "           'alpha': [1.0, 0]\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the function to get the combinations of parameters\n",
    "round(m.gridsearch (X_train_scaled, y_train, LassoLars() , params, 'neg_root_mean_squared_error'), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Feature Selection using Select K Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using my function for SelectkBest\n",
    "top_sb =m.select_kbest(X_train_scaled, y_train, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model and calculate RMSE\n",
    "lasso_skb = m.create_model(X_train_scaled[top_sb], y_train_df, 'actual', LassoLars(alpha = 1, normalize= True, fit_intercept= True), 'modelLasso' )\n",
    "round(lasso_skb['rmse'], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "clf = LassoLars(alpha = 1, normalize= False, fit_intercept= True)\n",
    "# cv = number of folds\n",
    "cross= cross_val_score(clf, X_train_scaled[top_sb], y_train, cv=3, scoring = 'neg_root_mean_squared_error')\n",
    "cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the lasso_skb model metrics to metric_df\n",
    "metric_df = metric_df.append(\n",
    "    {\n",
    "    'model': 'lasso_skb',\n",
    "    'rmse_train': lasso_skb['rmse'],    \n",
    "    'r^2' : lasso_skb['r2']}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Feature Selection using  RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the top 8 features\n",
    "top_rfe = m.select_rfe(X_train_scaled, y_train, 6, LassoLars(alpha = 1, normalize= True, fit_intercept= True) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the function to get the combinations of parameters\n",
    "round(m.gridsearch (X_train_scaled, y_train, LassoLars() , params, 'neg_root_mean_squared_error'), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model and calculate RMSE\n",
    "lasso_rfe = m.create_model(X_train_scaled[top_rfe], y_train_df, 'actual', LassoLars(alpha = 1, normalize= False, fit_intercept= True), 'modelLasso' )\n",
    "round(lasso_rfe['rmse'], 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "clf = LassoLars(alpha = 1, normalize= False, fit_intercept= True)\n",
    "# cv = number of folds\n",
    "cross = cross_val_score(clf, X_train_scaled[top_rfe], y_train, cv=3, scoring = 'neg_root_mean_squared_error')\n",
    "cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the lasso_rfe model to metric_df\n",
    "metric_df = metric_df.append(\n",
    "    {\n",
    "    'model': 'lasso_rfe',\n",
    "    'rmse_train': lasso_rfe['rmse'],    \n",
    "    'r^2' : lasso_rfe['r2']}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL 3: TweedieRegressor (GLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Hyperparameter optimization with Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the parameters we wish to use as a dictionary, then use that dictionary when we create the class.\n",
    "params = {\n",
    "          'power': [0.0, 1],\n",
    "           'fit_intercept' : [True , False],\n",
    "          'warm_start': [True, False], \n",
    "           'alpha': [1.0, 0.0]\n",
    "         }\n",
    "# use the function\n",
    "round(m.gridsearch (X_train_scaled, y_train,TweedieRegressor() , params, 'neg_root_mean_squared_error'), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Feature Selection using Select K Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using my function for SelectkBest\n",
    "top_sb =m.select_kbest(X_train_scaled, y_train, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model and calculate RMSE\n",
    "gml_skb = m.create_model(X_train_scaled[top_sb], y_train_df, 'actual',TweedieRegressor(alpha =0 , fit_intercept= True, power=0 ,\\\n",
    "                                                                  warm_start= False), 'modelgml' )\n",
    "round(gml_skb['rmse'], 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "clf = TweedieRegressor(alpha =0 , fit_intercept= True, power=0 ,warm_start= False)\n",
    "# cv = number of folds\n",
    "cross = cross_val_score(clf, X_train_scaled[top_sb], y_train, scoring = 'neg_root_mean_squared_error',cv=3)\n",
    "cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the gml_skb model to metric_df\n",
    "\n",
    "metric_df = metric_df.append(\n",
    "    {\n",
    "    'model': 'gml_skb',\n",
    "    'rmse_train': gml_skb['rmse'],    \n",
    "    'r^2' : gml_skb['r2']}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -  Feature Selection using  RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use function to get the top 8 features\n",
    "top_rfe = m.select_rfe(X_train_scaled, y_train, 7, TweedieRegressor(alpha =0 , fit_intercept= True, power=0 ,\\\n",
    "                                                                  warm_start= False) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model and calculate RMSE\n",
    "gml_rfe = m.create_model(X_train_scaled[top_rfe], y_train_df, 'actual',TweedieRegressor(alpha =0 , fit_intercept= True, power=0 ,\\\n",
    "                                                                  warm_start= False), 'modelgml' )\n",
    "round(gml_rfe['rmse'], 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "clf = TweedieRegressor(alpha =0 , fit_intercept= True, power=0 ,warm_start= False)\n",
    "# cv = number of folds\n",
    "cross = cross_val_score(clf, X_train_scaled[top_rfe], y_train, scoring = 'neg_root_mean_squared_error', cv=3)\n",
    "cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the gml_rfe model to metric_df\n",
    "metric_df = metric_df.append(\n",
    "    {\n",
    "    'model': 'gml_rfe',\n",
    "    'rmse_train': gml_rfe['rmse'],    \n",
    "    'r^2' : gml_rfe['r2']}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL 4: Polynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Feature Selection using  Select K Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use function to get the top 8 features\n",
    "top_sb =m.select_kbest(X_train_scaled, y_train, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the polynomial features to get a new set of features\n",
    "pf = PolynomialFeatures(degree = 2) \n",
    "\n",
    "# fit and transform X_train_scaled\n",
    "X_train_degree3 = pf.fit_transform(X_train_scaled[top_sb])\n",
    "\n",
    "# transform X_validate_scaled & X_test_scaled\n",
    "X_test_degree3 = pf.transform(X_test_scaled[top_sb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Hyperparameter optimization with Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the parameters we wish to use as a dictionary, then use that dictionary when we create the class.\n",
    "params = {\n",
    "          'normalize': [True, False],\n",
    "          'fit_intercept':[True, False],\n",
    "         }\n",
    "\n",
    "round(m.gridsearch (X_train_degree3, y_train, LinearRegression() , params, 'neg_root_mean_squared_error'), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model and calculate RMSE\n",
    "pol_skb = m.create_model(X_train_degree3, y_train_df, 'actual',LinearRegression( normalize=True, fit_intercept = True ), 'pol2_skb' )\n",
    "round(pol_skb['rmse'], 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "clf = LinearRegression( normalize=False, fit_intercept = True )\n",
    "# cv = number of folds\n",
    "cross = cross_val_score(clf, X_train_degree3, y_train, cv=5, scoring = 'neg_root_mean_squared_error')\n",
    "cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the pol_skb model to metric_df\n",
    "metric_df = metric_df.append(\n",
    "    {\n",
    "    'model': 'pol_skb',\n",
    "    'rmse_train': pol_skb['rmse'],    \n",
    "    'r^2' : pol_skb['r2']}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Feature Selection using  RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the top 8 features by RFE\n",
    "top_rfe_pol = m.select_rfe(X_train_scaled, y_train, 11, LinearRegression(normalize=False, fit_intercept = False) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the polynomial features to get a new set of features\n",
    "pf = PolynomialFeatures(degree = 2) \n",
    "\n",
    "# fit and transform X_train_scaled\n",
    "X_train_degree2 = pf.fit_transform(X_train_scaled[top_rfe_pol])\n",
    "\n",
    "# transform X_validate_scaled & X_test_scaled\n",
    "X_test_degree2 = pf.transform(X_test_scaled[top_rfe_pol])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Hyperparameter optimization with Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(m.gridsearch (X_train_degree2, y_train, LinearRegression() , params, 'neg_root_mean_squared_error'), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model and calculate RMSE\n",
    "pol_rfe = m.create_model(X_train_degree2, y_train_df, 'actual',LinearRegression( normalize=False, fit_intercept = False ), 'pol3_RFE' )\n",
    "round(pol_rfe['rmse'], 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "clf = LinearRegression( normalize=False, fit_intercept = False )\n",
    "# cv = number of folds\n",
    "cross = cross_val_score(clf, X_train_degree2, y_train, cv=5, scoring = 'neg_root_mean_squared_error')\n",
    "cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the pol_rfe model to metric_df\n",
    "metric_df = metric_df.append(\n",
    "    {\n",
    "    'model': 'pol_rfe',\n",
    "    'rmse_train': pol_rfe['rmse'],    \n",
    "    'r^2' : pol_rfe['r2']}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(metric_df.sort_values('rmse_train'), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The best model is' )\n",
    "round(metric_df.nsmallest(1, 'rmse_train'), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Findings and Takeaways**\n",
    "\n",
    "* Our top performing model is the Polynomial Regression 2nd Degree model utilizing the Recursive Feature Elimnation (RFE) feature selector\n",
    "    * According this this model, the top 11 selected features based on the the RFE class class are: ['this_week_sales', 'temperature', 'store_size', 'next_week_1_year_ago', 'christmas', 'pre_christmas', 'super_bowl', 'thanksgiving', 'avgMoM_perc_cpi', 'avgMoM_perc_unemp', 'avgQoQ_perc_unemp']\n",
    "    * Note: feature numbers varied by model and were chosen via an iterative process that sought out the best performing scenario\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use function to create and calculate the metrics\n",
    "pol_reg_test =  m.create_model(X_test_degree2, \n",
    "                              y_test_df, 'actual',LinearRegression( normalize=False, fit_intercept = True ), 'test_polreg' )\n",
    "\n",
    "round(pol_reg_test['rmse'], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The Baseline RMSE is $', round(rmse_baseline2_train,4))\n",
    "print('The Best Model RMSE on unseen data is $', round(pol_reg_test['rmse'],4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Key Findings and Takeaways:</b> Our Polynomial Regression model utilizing the RFE selector performed very well on the Test data set and showed no signs of being overfit. The difference in the Train and Test RMSE scores was roughly 1.7%.  Additionally, based on the RMSE scores, our model Test outperformed the Baseline by roughly 29%.    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Visual Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating R2 for our model predictions\n",
    "evs = explained_variance_score(y_train_df.actual, y_train_df.pol3_RFE)\n",
    "print('Explained Variance = ', round(evs,3))\n",
    "\n",
    "# Calculating R2 for our Baseline 2\n",
    "evs = explained_variance_score(y_train_df.actual, y_train_df.last_year_baseline)\n",
    "print('Explained Variance = ', round(evs,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.scatter(y_train_df.actual, y_train_df.last_year_baseline, alpha=.8, color=\"red\", label='baseline')\n",
    "plt.annotate(\"Baseline: Predict Using Mean\", (16, 9.5))\n",
    "plt.plot(y_train_df.actual, y_train_df.actual, alpha=.5, color=\"blue\", label='_nolegend_')\n",
    "plt.annotate(\"The Ideal Line: Predicted = Actual\", (.5, 3.5), rotation=15.5)\n",
    "\n",
    "plt.scatter(y_train_df.actual, y_train_df.modelgml, \n",
    "            alpha=.5, color=\"green\", s=100, label=\"Model: Tweedie Regressor\")\n",
    "plt.scatter(y_train_df.actual, y_train_df.modelOLS, \n",
    "            alpha=.5, color=\"yellow\", s=100, label=\"Model: OLS\")\n",
    "plt.scatter(y_train_df.actual, y_train_df.pol3_RFE, \n",
    "            alpha=.4, color=\"purple\", s=100, label=\"Model: Polynomial RFE\")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Actual Weekly Sales\")\n",
    "plt.ylabel(\"Predicted Weekly Sales\")\n",
    "plt.title(\"Model Evaluation: Model Predictions vs Actual Sales\")\n",
    "plt.ticklabel_format(style = 'plain')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Key Findings and Takeaways**\n",
    "\n",
    "* Based on our R2 scores, our baseline was a fairly predictive methodology and left a small window for improvement  \n",
    "    * 97.4% of the variance in our target could be explained by last year's sales data alone\n",
    "    * red dots in the chart above show how tight last year's sales data lies to the actual sales data our model was attempting to predict\n",
    "* Nevertheless, we were able to use the provided data, engineer a few features and successfully build a model that improved on the baseline and explains 98.7% of the target variance.  \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -  Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model\n",
    "pf = PolynomialFeatures(degree = 2)\n",
    "pf.fit_transform(X_train_scaled[top_rfe_pol])\n",
    "mod =LinearRegression( normalize=False, fit_intercept = False )\n",
    "mod.fit(X_train_degree2, y_train_df['actual'])\n",
    "X_train_top = X_train_scaled[top_rfe_pol]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -Get Features Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#create a df to store the features \n",
    "feature_importances = pd.DataFrame(mod.coef_, \n",
    "                                   index = pf.get_feature_names(X_train_top.columns), \n",
    "                                   columns=['importance']).sort_values('importance', ascending=False)\n",
    "\n",
    "#reset index\n",
    "feature_importances = feature_importances.reset_index().rename( columns ={'index': 'features'} )\n",
    "\n",
    "# Index should start at 1 so it can show the rank of each feature\n",
    "feature_importances.index = feature_importances.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new df, that have the top 5 positive and negative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df_top =pd.concat([feature_importances.head(10), feature_importances.tail(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "clrs = ['yellow' if (x < 0) else 'blue' for x in df_top.importance ]\n",
    "sns.barplot(x='importance', y = 'features', data = df_top , palette=clrs)\n",
    "plt.ylabel('')\n",
    "plt.yticks(size=16)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Most Important Polynomial Features', fontsize = 18)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion \n",
    "\n",
    "We successfully created a model that predicts next weeks sales better than the baseline by 29%. Showing that there is value in the external factors such as inflation, and unemployment, sales from the current week. \n",
    "\n",
    "With more time we would like to scale this model up or down. Perhaps clustering stores together to find similar economic regions. We would cluster stores together not just by size, but by similar changes in fuel prices, or unemployment numbers. This type of analysis could be of help to regional managers. Or perhaps we gather data by Walmart departments. While economic factors might have one effect on the stores as a whole, how do they affect different departments? Is the grocery department affected the same way as the electronics department?  \n",
    "\n",
    "\n",
    "Thank you for taking the time to read this notebook. \n",
    "\n",
    "<img src=\"https://i5.walmartimages.com/asr/e9f4a121-27fc-4226-b059-309ddd73615b_1.d55cf65a92feb2eacea4433c80d940c6.jpeg?odnWidth=1000&odnHeight=1000&odnBg=ffffff\" alt=\"Smile\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
