{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import wrangle\n",
    "import new_wrangle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# acquire data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic acquire data, we are not modifying anything. We just wan to see the data ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use function to acquire data\n",
    "df1= wrangle.acquire_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6435 entries, 0 to 6434\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Store         6435 non-null   int64  \n",
      " 1   Date          6435 non-null   object \n",
      " 2   Weekly_Sales  6435 non-null   float64\n",
      " 3   Holiday_Flag  6435 non-null   int64  \n",
      " 4   Temperature   6435 non-null   float64\n",
      " 5   Fuel_Price    6435 non-null   float64\n",
      " 6   CPI           6435 non-null   float64\n",
      " 7   Unemployment  6435 non-null   float64\n",
      " 8   Type          6435 non-null   object \n",
      " 9   Size          6435 non-null   int64  \n",
      "dtypes: float64(5), int64(3), object(2)\n",
      "memory usage: 553.0+ KB\n"
     ]
    }
   ],
   "source": [
    "#check  info\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6435, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways**\n",
    "- we have 10 columns and 6435 columns\n",
    "- no nulls\n",
    "- we nned to change some columns type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ouliers store_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are exploring the store_type vs store_size, we notice that there are outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x= df1['Type'], y= df1['Size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check only the outliers\n",
    "sns.boxplot(x= df1['Type'], y= df1['Size'])\n",
    "plt.ylim(0,46000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see there are outliers for B and A and we decided to change those to  store type C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting a df that has all store_size < 50000 and df.store_type != \"C\"\n",
    "df3 = df1 [(df1.Size < 50000) & (df1.Type != \"C\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets see which stores type A  are df.store_size < 50000\n",
    "df3[df3.Type == \"A\"].groupby('Store').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#lets see which stores type A  are df.store_size < 50000\n",
    "df3[df3.Type == \"B\"].groupby('Store').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways**\n",
    "- Instead of removing theses outliers, we decided to change them to the type based on the size.\n",
    "- I gave the store_id to Natasha so she is going to change the type in the wrangle function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the wrangle_walmar function is renaming columns, adding new columns, dummi variables, and set date as index (datetime type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#using the funcion wrangle\n",
    "df= new_wrangle.wrangle_walmart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#chec the data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#checking if the store_type has no outliers\n",
    "sns.boxplot(x= df['store_type'], y= df['store_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribution (df):\n",
    "    '''\n",
    "    takes in a df and plot individual variable distributions excluding object type\n",
    "    '''\n",
    "    plt.figure\n",
    "    plt.style.use(\"ggplot\")\n",
    "    cols =df.columns.to_list()\n",
    "    for col in cols:\n",
    "        if df[col].dtype != 'object':\n",
    "            plt.hist(df[col],color ='blue')\n",
    "            plt.title(f'Distribution of {col}')\n",
    "            plt.xlabel(col)\n",
    "            plt.ylabel('Number of Weeks ')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.ticklabel_format(style = 'plain')\n",
    "            \n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "distribution(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('store_type').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#let see distribution by store type\n",
    "store_type = [\"A\", \"B\", \"C\"]\n",
    "for store in store_type:\n",
    "    print(\"Store type: \", store)\n",
    "    distribution(df[df.store_type == store])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#how many stores are Type C\n",
    "len(df[df.store_type == 'C'].store_id.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storeid for type c\n",
    "df[df.store_type == 'C'].store_size.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#store if for type B\n",
    "df[df.store_type == 'B'].store_size.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many stores are Type B\n",
    "len(df[df.store_type == 'B'].store_id.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store_Id for type A\n",
    "df[df.store_type == 'A'].store_size.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##how many stores are Type A\n",
    "len(df[df.store_type == 'A'].store_id.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways**\n",
    "- after wrangle_walmar we ended with 29 columns, and 6435 observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid blue\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the following steps were done to complete the wrangle function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dummies "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we are going to create dummies for :\n",
    "- Holiday_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dummy variables for 5 columns\n",
    "def create_multiple_dummies (df, dumm_col = ['holiday_name', 'season', 'store_type', 'month', 'year']):\n",
    "    '''\n",
    "    Takes in a df and columns to create dummies.\n",
    "    retunr the original df with de new columns (dimmies)\n",
    "    '''\n",
    "    #the column year is an integer we need to conver as string\n",
    "    df['year']= df['year'].astype('string')\n",
    "    #create dummy variables \n",
    "    for col in dumm_col:\n",
    "        #create dummies\n",
    "        df_dummies = pd.get_dummies(df[col], dummy_na=False)\n",
    "        #  concat df_dummies with my df\n",
    "        df = pd.concat([df, df_dummies], axis =1)\n",
    "    #drop no_holiday columns and year\n",
    "    df = df.drop(columns = ['no_holiday', 'year'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummies (df, dumm_col = ['holiday_name']):\n",
    "    '''\n",
    "    Takes in a df and columns to create dummies.\n",
    "    retunr the original df with de new columns (dummies)\n",
    "    '''\n",
    "    #create dummy variables \n",
    "    for col in dumm_col:\n",
    "        #create dummies\n",
    "        df_dummies = pd.get_dummies(df[col], dummy_na=False)\n",
    "        #  concat df_dummies with my df\n",
    "        df = pd.concat([df, df_dummies], axis =1)\n",
    "    #drop no_holiday columns and year\n",
    "    df = df.drop(columns = ['no_holiday'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['holiday_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the function before I add it to .py file\n",
    "df2 = create_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#we need to create new columns  pre- christmas  and tax_season because on exploration(Alberto and Heather ) they found a peak in those dates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the previous weeks for christmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df2.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a new column for is pre_christmas\n",
    "\n",
    "-Christmas:\n",
    "\n",
    "    - 31-Dec-10,  (pre_christmas = 24-Dec-10, 17-Dec 10)\n",
    "    - 30-Dec-11, (pre_christmas = 23-Dec-11, 16-Dec 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new colum and add zeros to everything\n",
    "df2 ['pre_christmas'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the list for pre_christmas\n",
    "pre_c= ['2010-12-24', '2010-12-17', '2011-12-23', '2011-12-16']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add value 1 for only pre_christmas weeks\n",
    "#df2.loc[pre_c, 'pre_christmas'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK THE VALUES\n",
    "#df2['pre_christmas'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ADD TAX SEASON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  first 2 weeks of April\n",
    "- 2010-04-02 & 2010-04-09\n",
    "- 2011-04-01 & 2011-04-08\n",
    "- 2012-04-06 & 2012-04-13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crete a new column and assign 0 as value\n",
    "df2['tax_season'] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the list for tax\n",
    "tax= ['2010-04-02 ', '2010-04-09', '2011-04-01', '2011-04-08', '2012-04-06', '2012-04-13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add value 1 for only for the list above\n",
    "df2.loc[tax, 'tax_season'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK THE VALUES\n",
    "df2['tax_season'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**note :** before scaling we need to split our data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select only the numeric columns \n",
    "num_df = df2.select_dtypes(exclude='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split using a function\n",
    "train, test, X_train, y_train, X_test, y_test = new_wrangle.train_test(num_df, 'weekly_sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports to scale\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_df ( train_df , test_df, columns,  scaler):\n",
    "    '''\n",
    "    Take in a 3 df and a type of scaler that you  want to  use. it will scale all columns\n",
    "    except object type. Fit a scaler only in train and tramnsform in train, validate and test.\n",
    "    returns  new dfs with the scaled columns.\n",
    "    scaler : MinMaxScaler() or RobustScaler(), StandardScaler() \n",
    "    Example:\n",
    "    scaled_df( X_train , X_test, columns , RobustScaler())\n",
    "    \n",
    "    '''\n",
    "    #import\n",
    "    from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "    # fit our scaler\n",
    "    scaler.fit(train_df[columns])\n",
    "    # get our scaled arrays\n",
    "    train_scaled = scaler.transform(train_df[columns])\n",
    "    test_scaled= scaler.transform(test_df[columns])\n",
    "\n",
    "    # convert arrays to dataframes\n",
    "    train_scaled_df = pd.DataFrame(train_scaled, columns=columns).set_index([train_df.index.values])\n",
    "    test_scaled_df = pd.DataFrame(test_scaled, columns=columns).set_index([test_df.index.values])\n",
    "\n",
    "#     #add the columns that are not scaled\n",
    "#     train_scaled_df = pd.concat([train_scaled_df, train_df.drop(columns = columns) ], axis= 1 )\n",
    "#     test_scaled_df = pd.concat([test_scaled_df, test_df.drop(columns = columns) ], axis= 1 )\n",
    "    #plot\n",
    "    for col in columns: \n",
    "        plt.figure(figsize=(13, 6))\n",
    "        plt.subplot(121)\n",
    "        plt.hist(train_df[col], ec='black')\n",
    "        plt.title('Original')\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel(\"counts\")\n",
    "        plt.subplot(122)\n",
    "        plt.hist(train_scaled_df[col],  ec='black')\n",
    "        plt.title('Scaled')\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel(\"counts\")\n",
    "\n",
    "\n",
    "\n",
    "    return train_scaled_df,  test_scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns =  X_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#test the function\n",
    "#train_Xscaled_df,  test_Xscaled_df= scaled_df( X_train , X_test, columns , MinMaxScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(df, target):\n",
    "    '''\n",
    "    This function brings in the dataframe and the target feature\n",
    "    then returns X_train, y_train, X_test and y_test with their respective shapes\n",
    "    '''\n",
    "    train = df[:'05-2012'] # includes everything until june 2016\n",
    "    test = df['06-2012':\"2012\"] #includes last 6 months\n",
    "\n",
    "    # split train into X (dataframe, drop target) & y (series, keep target only)\n",
    "    X_train = train.drop(columns=[target])\n",
    "    y_train = train[target]\n",
    "\n",
    "    # split test into X (dataframe, drop target) & y (series, keep target only)\n",
    "    X_test = test.drop(columns=[target])\n",
    "    y_test = test[target]\n",
    "\n",
    "    # Have function print datasets shape\n",
    "    print(f'X_train -> {X_train.shape}')\n",
    "    print(f'X_test -> {X_test.shape}')\n",
    "\n",
    "    return train, X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_scale and scale (df, target, scaler):\n",
    "    '''\n",
    "    takes in a df and creates dummy variables, select only the numeric columns and  split into X_train, y_train, \n",
    "    X_test, y_test and scaled X_train, X_test.\n",
    "    return   X_train_scaled, y_train_scaled, X_test, y_test\n",
    "    '''\n",
    "\n",
    "\n",
    "\n",
    "    #split\n",
    "    train, X_train, y_train, X_test, y_test = train_test(num_df, target)\n",
    "\n",
    "    #select the columns to scale\n",
    "    columns =  X_train.select_dtypes(exclude='object').columns.to_list()\n",
    "    #scale \n",
    "    X_train_scaled, X_test_scaled = scaled_df( X_train , X_test, columns , scaler)\n",
    "\n",
    "    return train, X_train_scaled, X_test_scaled, y_train, y_test\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split\n",
    "train, test, X_train, y_train, X_test, y_test = new_wrangle.train_test(df, 'weekly_sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the columns to scale\n",
    "col =  X_train.select_dtypes(exclude='object').columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale \n",
    "X_train_scaled, X_test_scaled = scaled_df( X_train , X_test, col , MinMaxScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train, X_train_scaled, y_train_scaled, X_test, y_test = prepare_modeling_dummies (df, 'weekly_sales', MinMaxScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train, test,  X_train_scaled, X_test_scaled, y_train, y_test = new_wrangle.split_scale(df, 'weekly_sales', MinMaxScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle and split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's test the functions wrangle and split and scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =new_wrangle.wrangle_walmart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 6435 entries, 2010-02-05 to 2012-10-26\n",
      "Data columns (total 29 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   store_id            6435 non-null   object \n",
      " 1   weekly_sales        6435 non-null   float64\n",
      " 2   holiday_flag        6435 non-null   int64  \n",
      " 3   temperature         6435 non-null   int64  \n",
      " 4   fuel_price          6435 non-null   float64\n",
      " 5   inflation           6435 non-null   float64\n",
      " 6   unemployment        6435 non-null   float64\n",
      " 7   store_type          6435 non-null   object \n",
      " 8   store_size          6435 non-null   int64  \n",
      " 9   month               6435 non-null   object \n",
      " 10  year                6435 non-null   int64  \n",
      " 11  quarter             6435 non-null   int64  \n",
      " 12  weekday             6435 non-null   object \n",
      " 13  week_of_year        6435 non-null   int64  \n",
      " 14  deflated_series     6435 non-null   float64\n",
      " 15  sales_delta_weekly  6435 non-null   float64\n",
      " 16  sales_delta_yearly  6435 non-null   float64\n",
      " 17  gas_delta_weekly    6435 non-null   float64\n",
      " 18  gas_delta_yearly    6435 non-null   float64\n",
      " 19  season              6435 non-null   object \n",
      " 20  holiday_name        6435 non-null   object \n",
      " 21  last_year_sales     4095 non-null   float64\n",
      " 22  last_week_sales     6390 non-null   float64\n",
      " 23  christmas           6435 non-null   uint8  \n",
      " 24  labor_day           6435 non-null   uint8  \n",
      " 25  pre_christmas       6435 non-null   uint8  \n",
      " 26  super_bowl          6435 non-null   uint8  \n",
      " 27  tax_season          6435 non-null   uint8  \n",
      " 28  thanksgiving        6435 non-null   uint8  \n",
      "dtypes: float64(11), int64(6), object(6), uint8(6)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**  we have nulls in our df because we created a new column last_year_sales that's why the fisrt year has nulls because we dond have information about the previous year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6435, 29)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no_holiday       5535\n",
       "tax_season        270\n",
       "pre_christmas     180\n",
       "labor_day         135\n",
       "super_bowl        135\n",
       "thanksgiving       90\n",
       "christmas          90\n",
       "Name: holiday_name, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.holiday_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop nulls\n",
    "df2= df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4095, 29)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -> (2866, 30)\n",
      "test -> (1229, 30)\n"
     ]
    }
   ],
   "source": [
    "train, test,  X_train_scaled, X_test_scaled, y_train, y_test = new_wrangle.split_scale(df2, 'weekly_sales', MinMaxScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2866 entries, 2011-07-08_store_14 to 2012-08-10_store_32\n",
      "Data columns (total 30 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Date                2866 non-null   object \n",
      " 1   store_id            2866 non-null   object \n",
      " 2   weekly_sales        2866 non-null   float64\n",
      " 3   holiday_flag        2866 non-null   int64  \n",
      " 4   temperature         2866 non-null   int64  \n",
      " 5   fuel_price          2866 non-null   float64\n",
      " 6   inflation           2866 non-null   float64\n",
      " 7   unemployment        2866 non-null   float64\n",
      " 8   store_type          2866 non-null   object \n",
      " 9   store_size          2866 non-null   int64  \n",
      " 10  month               2866 non-null   object \n",
      " 11  year                2866 non-null   int64  \n",
      " 12  quarter             2866 non-null   int64  \n",
      " 13  weekday             2866 non-null   object \n",
      " 14  week_of_year        2866 non-null   int64  \n",
      " 15  deflated_series     2866 non-null   float64\n",
      " 16  sales_delta_weekly  2866 non-null   float64\n",
      " 17  sales_delta_yearly  2866 non-null   float64\n",
      " 18  gas_delta_weekly    2866 non-null   float64\n",
      " 19  gas_delta_yearly    2866 non-null   float64\n",
      " 20  season              2866 non-null   object \n",
      " 21  holiday_name        2866 non-null   object \n",
      " 22  last_year_sales     2866 non-null   float64\n",
      " 23  last_week_sales     2866 non-null   float64\n",
      " 24  christmas           2866 non-null   uint8  \n",
      " 25  labor_day           2866 non-null   uint8  \n",
      " 26  pre_christmas       2866 non-null   uint8  \n",
      " 27  super_bowl          2866 non-null   uint8  \n",
      " 28  tax_season          2866 non-null   uint8  \n",
      " 29  thanksgiving        2866 non-null   uint8  \n",
      "dtypes: float64(11), int64(6), object(7), uint8(6)\n",
      "memory usage: 576.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2866 entries, 2011-07-08_store_14 to 2012-08-10_store_32\n",
      "Data columns (total 22 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   holiday_flag        2866 non-null   float64\n",
      " 1   temperature         2866 non-null   float64\n",
      " 2   fuel_price          2866 non-null   float64\n",
      " 3   inflation           2866 non-null   float64\n",
      " 4   unemployment        2866 non-null   float64\n",
      " 5   store_size          2866 non-null   float64\n",
      " 6   year                2866 non-null   float64\n",
      " 7   quarter             2866 non-null   float64\n",
      " 8   week_of_year        2866 non-null   float64\n",
      " 9   deflated_series     2866 non-null   float64\n",
      " 10  sales_delta_weekly  2866 non-null   float64\n",
      " 11  sales_delta_yearly  2866 non-null   float64\n",
      " 12  gas_delta_weekly    2866 non-null   float64\n",
      " 13  gas_delta_yearly    2866 non-null   float64\n",
      " 14  last_year_sales     2866 non-null   float64\n",
      " 15  last_week_sales     2866 non-null   float64\n",
      " 16  christmas           2866 non-null   float64\n",
      " 17  labor_day           2866 non-null   float64\n",
      " 18  pre_christmas       2866 non-null   float64\n",
      " 19  super_bowl          2866 non-null   float64\n",
      " 20  tax_season          2866 non-null   float64\n",
      " 21  thanksgiving        2866 non-null   float64\n",
      "dtypes: float64(22)\n",
      "memory usage: 515.0+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#explore our target\n",
    "plt.figure(figsize=(8, 10))\n",
    "sns.histplot(train,\n",
    "                 x=train['weekly_sales'],\n",
    "                 #hue='loan_status',\n",
    "                 multiple='layer'\n",
    "                 )\n",
    "plt.title(\"Distribution of Loan Status\")\n",
    "plt.xlabel('Weekly sales in dollars')\n",
    "plt.ylabel('Number of weeks')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ticklabel_format(style = 'plain')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(train['weekly_sales'])\n",
    "plt.xticks(rotation=45)\n",
    "#plt.ticklabel_format(style = 'plain')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(train['weekly_sales'])\n",
    "plt.xlim(2500000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "sns.heatmap(train.corr(), cmap='coolwarm', annot=True, linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the relation of my target with all the featues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#let's focus on my target\n",
    "plt.figure(figsize=(8, 12))\n",
    "heatmap = sns.heatmap(train.corr()[['weekly_sales']].sort_values(by='weekly_sales', ascending=False), vmin=-3, vmax=3, annot=True, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**takeaways**\n",
    "- last week_sales, last_year_sales and store_size have stroger correlation with out target\n",
    "- pre_christmas has also a positive correlation\n",
    "- we can not use deflated_series because was calculated using our target\n",
    "- negative correlation unemployment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration target vs Fearture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -  weekly_sales vs store_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "sns.jointplot(x= 'weekly_sales', y= 'store_size', data = train, hue ='season')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "**takeaways**\n",
    "- the small the store, less weekly sales\n",
    "- winter has the greater weekly sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -  weekly_sales vs temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "sns.jointplot(x= 'weekly_sales', y= 'temperature', data = train, hue= \"season\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways**\n",
    "- Winter and fall have the greater weekly_sales. may it is because of christmas and blackfriday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# winter_df = train[train.season == \"Winter\"][['weekly_sales', 'temperature', 'season']]\n",
    "# winter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sns.jointplot(x= 'weekly_sales', y= 'temperature', data = winter_df, hue= \"season\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.season.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_list = ['blue','green', 'red', 'orange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for season, color in zip(train.season.unique(), color_list):\n",
    "    print(season, color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for season, c in zip(train.season.unique(), color_list):\n",
    "    print(season)\n",
    "    sns.jointplot(x= 'weekly_sales', y= 'temperature', data = train[train.season==season], color= c)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -  weekly_sales vs holiday_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "sns.boxplot(x= train['holiday_name'], y =train['weekly_sales'] )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways**\n",
    "- the 2 holidays with the greatest weekle_sales are pre_christmas and thanksgiving\n",
    "-we can see christmas does not have large amount of weekly_sales it is because the people buy before christmas , it is not like blackfriday that the people actually buy in this specific week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - weekly_sales vs season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "sns.boxplot(x= train['season'], y =train['weekly_sales'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**takeaways**\n",
    "- we see some outliers but basically there are the weekly sales for thanksgiving and christmas (pre)\n",
    "- we can say summer has the lowest range of weekly sales amout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for season, c in zip(train.season.unique(), color_list):\n",
    "    print(season)\n",
    "    sns.boxplot(x= train[train.season== season]['weekly_sales'], color = c )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**takeaways**\n",
    "- it looks like summer has the lowest median "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor \n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# #conver y_train y _ validate to df\n",
    "y_train_df = pd.DataFrame( {'actual': y_train})\n",
    "y_test_df = pd.DataFrame( {'actual': y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_kbest  (X_df, y_df, n_features):\n",
    "    '''\n",
    "    Takes in the predictors, the target, and the number of features to select (k) ,\n",
    "    and returns the names of the top k selected features based on the SelectKBest class\n",
    "    \n",
    "    X_df : the predictors\n",
    "    y_df : the target\n",
    "    n_features : the number of features to select (k)\n",
    "    Example\n",
    "    select_kbest(X_train_scaled, y_train, 2)\n",
    "    '''\n",
    "    \n",
    "    f_selector = SelectKBest(score_func=f_regression, k= n_features)\n",
    "    f_selector.fit(X_df, y_df)\n",
    "    mask = f_selector.get_support()\n",
    "    X_df.columns[mask]\n",
    "    top = list(X_df.columns[mask])\n",
    "    print(f'The top {n_features} selected feautures based on the SelectKBest class are: {top}' )\n",
    "    return top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_rfe (X_df, y_df, n_features, method):\n",
    "    '''\n",
    "    Takes in the predictors, the target, and the number of features to select (k) ,\n",
    "    and returns the names of the top k selected features based on the Recursive Feature Elimination (RFE)\n",
    "    \n",
    "    X_df : the predictors\n",
    "    y_df : the target\n",
    "    n_features : the number of features to select (k)\n",
    "    method : LinearRegression, LassoLars, TweedieRegressor\n",
    "    Example\n",
    "    select_rfe(X_train_scaled, y_train, 2, LinearRegression())\n",
    "    '''\n",
    "    lm = method\n",
    "    rfe = RFE(estimator=lm, n_features_to_select= n_features)\n",
    "    rfe.fit(X_df, y_df)\n",
    "    top_rfe = list(X_df.columns[rfe.support_])\n",
    "    print(f'The top {n_features} selected feautures based on the the RFE class class are: {top_rfe}' )\n",
    "    print(pd.Series(dict(zip(X_df.columns, rfe.ranking_))).sort_values())\n",
    "    return top_rfe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_errors(df, y, yhat):\n",
    "    '''\n",
    "    Takes in a dataframe , y = column with actual_values and yhat= name of the columns with predicted_values\n",
    "    and calculate:\n",
    "    sum of squared errors (SSE)\n",
    "    explained sum of squares (ESS)\n",
    "    total sum of squares (TSS)\n",
    "    mean squared error (MSE)\n",
    "    root mean squared error (RMSE)\n",
    "    Returns a dictionary with all these values.\n",
    "    Example:\n",
    "    plot_residuals(df, 'tip', 'yhat')\n",
    "    '''\n",
    "    #import\n",
    "    from sklearn.metrics import  mean_squared_error\n",
    "    from math import sqrt\n",
    "    \n",
    "    \n",
    "    #calculate SSE using sklearn\n",
    "    SSE = mean_squared_error(df[y], df[yhat])*len(df)\n",
    "    #explained sum of squares (ESS)\n",
    "    ESS = ((df[yhat] - df[y].mean())**2).sum()\n",
    "    #total sum of squares (TSS)\n",
    "    TSS = ((df[y] - df[y].mean())**2).sum()\n",
    "    #mean squared error (MSE)\n",
    "    MSE = mean_squared_error(df[y], df[yhat])\n",
    "    #root mean squared error (RMSE)\n",
    "    RMSE = sqrt(MSE)\n",
    "    \n",
    "    #create a dictionary\n",
    "    m= {\n",
    "        'sse': SSE,\n",
    "        'ess': ESS,\n",
    "        'rmse': RMSE,\n",
    "        'tss': TSS,\n",
    "        'mse': MSE,\n",
    "        'r2': ESS/TSS,\n",
    "    }\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model (X_df_scaled, y_df, actual, method, name):\n",
    "    '''\n",
    "    takes in features scaled df, target df, name of actual target, \n",
    "    type of method and the name of the selected method and \n",
    "    returns a dictionary that contains calculated regression errors.\n",
    "    \n",
    "    X_df_scaled : df that contains scaled featues\n",
    "    y_df: target df\n",
    "    actual: name of the column where is actual value of the target\n",
    "    mehod: type of method to create the model object\n",
    "    name: enter the new name for your model\n",
    "    \n",
    "    Example:\n",
    "    create_model(X_train_scaled[top_sb], y_train, 'actual', LinearRegression(normalize=True), 'modelOLS' )\n",
    "    '''\n",
    "    # fit the thing\n",
    "    method.fit(X_df_scaled, y_df[actual])\n",
    "\n",
    "    # predict train\n",
    "    y_df[name] = method.predict(X_df_scaled)\n",
    "\n",
    "    #calculate regression errors using a created function\n",
    "    train_eval = regression_errors(y_df, actual, name)\n",
    "\n",
    "    return train_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(metric_df):\n",
    "    \n",
    "    from IPython.display import display, HTML\n",
    "    rmse_base = metric_df.iloc[0,2]\n",
    "    print(f'These are the models that perform better than our baseline rmse: {rmse_base}')\n",
    "    dfs =metric_df[['model', 'rmse_validate']][metric_df['rmse_validate'] < rmse_base]\n",
    "    display(HTML(dfs.to_html()))\n",
    "    \n",
    "    \n",
    "    min_val = metric_df['rmse_validate'].idxmin()\n",
    "    metric_df.iloc[min_val][0]\n",
    "    rsme_bet = round(metric_df['rmse_validate'].iloc[min_val], 2)\n",
    "    print('-----------------------------------------------------------------------------------------------')\n",
    "    print(f'   ********** The model with the less  rmse_validate  is {metric_df.iloc[min_val][0] }  rmse:{rsme_bet} **********             ')\n",
    "    print('-----------------------------------------------------------------------------------------------')\n",
    "    print(' ')\n",
    "    min_val = metric_df['r^2_validate'].idxmax()\n",
    "    metric_df.iloc[min_val][0]\n",
    "    print(f'The model with r^2 validate closer to 1 is ', metric_df.iloc[min_val][0])\n",
    "    \n",
    "    display(HTML(metric_df.to_html()))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_errors(df, y, option ):\n",
    "    '''\n",
    "    Takes in a dataframe , y = column with actual_values \n",
    "    and calculate:\n",
    "    sum of squared errors (SSE)\n",
    "    explained sum of squares (ESS)\n",
    "    total sum of squares (TSS)\n",
    "    mean squared error (MSE)\n",
    "    root mean squared error (RMSE)\n",
    "    Returns a dictionary with all these values\n",
    "    Example:\n",
    "    baseline_mean_errors(y_train, 'actual')\n",
    "    '''\n",
    "    #import\n",
    "    from sklearn.metrics import  mean_squared_error\n",
    "    from math import sqrt\n",
    "\n",
    "    #baseline\n",
    "    if option == 'mean':\n",
    "        df['yhat_baseline_mean'] = df[y].mean()\n",
    "        col = 'yhat_baseline_mean'\n",
    "    elif option == 'median':\n",
    "        df['yhat_baseline_median'] = df[y].median()\n",
    "        col = 'yhat_baseline_median'\n",
    "    else:\n",
    "        return print(\"please select the correct option: 'mean' or 'median' \")\n",
    "        \n",
    "    \n",
    "\n",
    "    #calculate SSE using sklearn\n",
    "    SSE_baseline = mean_squared_error(df[y], df[col])*len(df)\n",
    "    #explained sum of squares (ESS)\n",
    "    ESS_b = ((df[col] - df[y].mean())**2).sum()\n",
    "    #total sum of squares (TSS)\n",
    "    TSS_b = ((df[y] - df[y].mean())**2).sum()\n",
    "    #mean squared error (MSE)\n",
    "    MSE_baseline = mean_squared_error(df[y], df[col])\n",
    "    #root mean squared error (RMSE)\n",
    "    RMSE_baseline = sqrt(MSE_baseline)\n",
    "    \n",
    "    #create dicc\n",
    "    b ={\n",
    "        'sse': SSE_baseline,\n",
    "        'mse': MSE_baseline,\n",
    "        'rmse': RMSE_baseline,\n",
    "         'tss': TSS_b,\n",
    "        'ess' : ESS_b,\n",
    "        'mse': MSE_baseline,\n",
    "        'r2': ESS_b/TSS_b,       \n",
    "    }\n",
    "\n",
    "    return b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Baseline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1044296.2597557559"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "957922.2949999999"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "563052.7256939057"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create baseline using mean (I'm using my function to calculate rmse)\n",
    "tra = baseline_errors(y_train_df, 'actual', 'mean')\n",
    "tra['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a df to store metrics\n",
    "metric_df = pd.DataFrame(data = [{\n",
    "    'model': 'mean_baseline',\n",
    "    'rmse_train' : round(tra['rmse'], 2),\n",
    "    'r^2' : 0}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>rmse_train</th>\n",
       "      <th>r^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean_baseline</td>\n",
       "      <td>563052.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model  rmse_train  r^2\n",
       "0  mean_baseline   563052.73    0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - select k best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the columns that are related with our target\n",
    "X_train_scaled = X_train_scaled.drop(columns = ['deflated_series','sales_delta_weekly','sales_delta_yearly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled =   X_test_scaled.drop(columns = ['deflated_series','sales_delta_weekly','sales_delta_yearly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 6 selected feautures based on the SelectKBest class are: ['unemployment', 'store_size', 'last_year_sales', 'last_week_sales', 'pre_christmas', 'thanksgiving']\n"
     ]
    }
   ],
   "source": [
    "#using my function for SelectkBest\n",
    "top_sb =select_kbest(X_train_scaled, y_train, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  LinearRegression (OLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 8 selected feautures based on the the RFE class class are: ['holiday_flag', 'unemployment', 'last_year_sales', 'last_week_sales', 'christmas', 'labor_day', 'super_bowl', 'thanksgiving']\n",
      "holiday_flag         1\n",
      "super_bowl           1\n",
      "labor_day            1\n",
      "christmas            1\n",
      "last_week_sales      1\n",
      "last_year_sales      1\n",
      "thanksgiving         1\n",
      "unemployment         1\n",
      "week_of_year         2\n",
      "quarter              3\n",
      "pre_christmas        4\n",
      "store_size           5\n",
      "fuel_price           6\n",
      "year                 7\n",
      "gas_delta_yearly     8\n",
      "temperature          9\n",
      "inflation           10\n",
      "gas_delta_weekly    11\n",
      "tax_season          12\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "top_rfe = select_rfe(X_train_scaled, y_train, 8,LinearRegression(normalize=True, fit_intercept=True ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9826501779236793"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the model\n",
    "clf = LinearRegression(normalize=True)\n",
    "#cv = number of folds\n",
    "cross_val_score(clf, X_train_scaled, y_train, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['explained_variance', 'r2', 'max_error', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_root_mean_squared_error', 'neg_mean_poisson_deviance', 'neg_mean_gamma_deviance', 'accuracy', 'roc_auc', 'roc_auc_ovr', 'roc_auc_ovo', 'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'neg_brier_score', 'adjusted_rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.metrics.SCORERS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9826501779236793"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the model\n",
    "clf = LinearRegression(normalize=True)\n",
    "#cv = number of folds\n",
    "cross_val_score(clf, X_train_scaled, y_train, cv=5, scoring = 'r2').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-73910.79537108631"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the model\n",
    "clf = LinearRegression(normalize=True)\n",
    "#cv = number of folds\n",
    "cross_val_score(clf, X_train_scaled, y_train, cv=5, scoring = 'neg_root_mean_squared_error').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9825943012738833"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the model\n",
    "clf = LinearRegression(normalize=False)\n",
    "#cv = number of folds\n",
    "cross_val_score(clf, X_train_scaled, y_train, cv=3).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearch ( X_df , y_df , model, params, score):\n",
    "    '''\n",
    "    '''\n",
    "    grid = GridSearchCV(model, params, cv=5, scoring= score )\n",
    "    grid.fit(X_df, y_df)\n",
    "    #see the cross validation results in the cv_results_ property of the object we created.\n",
    "    results = grid.cv_results_\n",
    "    # I will use mean_test_score\n",
    "    test_scores = results['mean_test_score']\n",
    "    #GETTING THE PARAMETERS\n",
    "    params = results['params']\n",
    "    #We can combine these features together into a data frame to see how our different models perform:\n",
    "    for p, s in zip(params, test_scores):\n",
    "        p['score'] = s\n",
    "\n",
    "    return pd.DataFrame(params).sort_values(by='score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearRegression(),\n",
       "             param_grid={'fit_intercept': [True, False],\n",
       "                         'normalize': [True, False]},\n",
       "             scoring='neg_root_mean_squared_error')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#specify the parameters we wish to use as a dictionary, then use that dictionary when we create the class.\n",
    "params = {'normalize': [ True, False],\n",
    "          'fit_intercept': [True, False]}\n",
    "\n",
    "ols = LinearRegression()\n",
    "\n",
    "grid = GridSearchCV(ols, params, cv=5, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_fit_intercept', 'param_normalize', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see the cross validation results in the cv_results_ property of the object we created.\n",
    "results = grid.cv_results_\n",
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-73910.79537109, -73902.8390497 , -77238.39566647, -77238.39566647])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will use mean_test_score\n",
    "test_scores = results['mean_test_score']\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'fit_intercept': True, 'normalize': True},\n",
       " {'fit_intercept': True, 'normalize': False},\n",
       " {'fit_intercept': False, 'normalize': True},\n",
       " {'fit_intercept': False, 'normalize': False}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = results['params']\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_intercept</th>\n",
       "      <th>normalize</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-77238.395666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-77238.395666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-73910.795371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-73902.839050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_intercept  normalize         score\n",
       "2          False       True -77238.395666\n",
       "3          False      False -77238.395666\n",
       "0           True       True -73910.795371\n",
       "1           True      False -73902.839050"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can combine these features together into a data frame to see how our different models perform:\n",
    "for p, s in zip(params, test_scores):\n",
    "    p['score'] = s\n",
    "\n",
    "pd.DataFrame(params).sort_values(by='score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify the parameters we wish to use as a dictionary, then use that dictionary when we create the class.\n",
    "params = {'normalize': [ True, False],\n",
    "          'fit_intercept': [True, False]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_intercept</th>\n",
       "      <th>normalize</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-77238.395666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-77238.395666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-73910.795371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-73902.839050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_intercept  normalize         score\n",
       "2          False       True -77238.395666\n",
       "3          False      False -77238.395666\n",
       "0           True       True -73910.795371\n",
       "1           True      False -73902.839050"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch (X_train_scaled, y_train, LinearRegression() , params, 'neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_intercept</th>\n",
       "      <th>normalize</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.981057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.981057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.982650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.982654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_intercept  normalize     score\n",
       "2          False       True  0.981057\n",
       "3          False      False  0.981057\n",
       "0           True       True  0.982650\n",
       "1           True      False  0.982654"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch (X_train_scaled, y_train, LinearRegression() , params, 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OLS uising  select K best (6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75736.89572808747"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols_rfe = create_model(X_train_scaled[top_sb], y_train_df, 'actual', LinearRegression(normalize=True, fit_intercept=True ), 'modelOLS' )\n",
    "ols_rfe['rmse']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OLS uising  RFE (8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74557.20308979187"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols_rfe = create_model(X_train_scaled[top_rfe], y_train_df, 'actual', LinearRegression(normalize=True, fit_intercept=True ), 'modelOLS' )\n",
    "ols_rfe['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df = metric_df.append(\n",
    "    {\n",
    "    'model': 'ols_rfe',\n",
    "    'rmse_train': ols_rfe['rmse'],    \n",
    "    'r^2' : ols_rfe['r2']}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>rmse_train</th>\n",
       "      <th>r^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean_baseline</td>\n",
       "      <td>563052.73000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ols_rfe</td>\n",
       "      <td>74557.20309</td>\n",
       "      <td>0.982213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model    rmse_train       r^2\n",
       "0  mean_baseline  563052.73000  0.000000\n",
       "1        ols_rfe   74557.20309  0.982213"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LassoLars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify the parameters we wish to use as a dictionary, then use that dictionary when we create the class.\n",
    "params = {\n",
    "          'normalize': [True, False],\n",
    "          'fit_intercept':[True, False],\n",
    "           'alpha': [1.0, 0]\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LassoLars(alpha=0.5)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " LassoLars(alpha = .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>fit_intercept</th>\n",
       "      <th>normalize</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-77238.395666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-77238.395666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-77238.217188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-77238.217188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-73876.481581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-73876.481581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-73875.993658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-73873.466172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alpha  fit_intercept  normalize         score\n",
       "6    0.0          False       True -77238.395666\n",
       "7    0.0          False      False -77238.395666\n",
       "2    1.0          False       True -77238.217188\n",
       "3    1.0          False      False -77238.217188\n",
       "5    0.0           True      False -73876.481581\n",
       "4    0.0           True       True -73876.481581\n",
       "1    1.0           True      False -73875.993658\n",
       "0    1.0           True       True -73873.466172"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch (X_train_scaled, y_train, LassoLars(alpha = 1) , params, 'neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "###RFE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 8 selected feautures based on the the RFE class class are: ['unemployment', 'quarter', 'week_of_year', 'last_year_sales', 'last_week_sales', 'christmas', 'pre_christmas', 'thanksgiving']\n",
      "thanksgiving         1\n",
      "pre_christmas        1\n",
      "christmas            1\n",
      "last_week_sales      1\n",
      "unemployment         1\n",
      "last_year_sales      1\n",
      "quarter              1\n",
      "week_of_year         1\n",
      "store_size           2\n",
      "holiday_flag         3\n",
      "fuel_price           4\n",
      "year                 5\n",
      "gas_delta_yearly     6\n",
      "temperature          7\n",
      "inflation            8\n",
      "super_bowl           9\n",
      "gas_delta_weekly    10\n",
      "tax_season          11\n",
      "labor_day           12\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "top_rfe = select_rfe(X_train_scaled, y_train, 8, LassoLars(alpha = 1, normalize= True, fit_intercept= True) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74486.97741108827"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_rfe = create_model(X_train_scaled[top_rfe], y_train_df, 'actual', LassoLars(alpha = 1, normalize= False, fit_intercept= True), 'modelLasso' )\n",
    "lasso_rfe['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 8 selected feautures based on the SelectKBest class are: ['temperature', 'unemployment', 'store_size', 'week_of_year', 'last_year_sales', 'last_week_sales', 'pre_christmas', 'thanksgiving']\n"
     ]
    }
   ],
   "source": [
    "#using my function for SelectkBest\n",
    "top_sb =select_kbest(X_train_scaled, y_train, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75600.32914698498"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_skb = create_model(X_train_scaled[top_sb], y_train_df, 'actual', LassoLars(alpha = 1, normalize= False, fit_intercept= True), 'modelLasso' )\n",
    "lasso_skb['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74486.97741108827"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_rfe = create_model(X_train_scaled[top_rfe], y_train_df, 'actual', LassoLars(alpha = 1, normalize= False, fit_intercept= True), 'modelLasso' )\n",
    "lasso_rfe['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df = metric_df.append(\n",
    "    {\n",
    "    'model': 'lasso_rfe',\n",
    "    'rmse_train': lasso_rfe['rmse'],    \n",
    "    'r^2' : lasso_rfe['r2']}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>rmse_train</th>\n",
       "      <th>r^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean_baseline</td>\n",
       "      <td>563052.730000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ols_rfe</td>\n",
       "      <td>74557.203090</td>\n",
       "      <td>0.982213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lasso_rfe</td>\n",
       "      <td>74486.977411</td>\n",
       "      <td>0.982473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model     rmse_train       r^2\n",
       "0  mean_baseline  563052.730000  0.000000\n",
       "1        ols_rfe   74557.203090  0.982213\n",
       "2      lasso_rfe   74486.977411  0.982473"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## TweedieRegressor (GLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify the parameters we wish to use as a dictionary, then use that dictionary when we create the class.\n",
    "params = {\n",
    "          'power': [0.0, 1],\n",
    "           'fit_intercept' : [True , False],\n",
    "          'warm_start': [True, False], \n",
    "           'alpha': [1.0, 0.0]\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>fit_intercept</th>\n",
       "      <th>power</th>\n",
       "      <th>warm_start</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.937236e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.937236e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.937051e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.937051e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-5.505112e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-5.505112e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-5.012175e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-5.012175e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.467103e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.467103e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.467062e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.467062e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-7.723841e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-7.723841e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-7.387622e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-7.387622e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    alpha  fit_intercept  power  warm_start         score\n",
       "6     1.0          False    1.0        True -1.937236e+06\n",
       "7     1.0          False    1.0       False -1.937236e+06\n",
       "14    0.0          False    1.0        True -1.937051e+06\n",
       "15    0.0          False    1.0       False -1.937051e+06\n",
       "4     1.0          False    0.0        True -5.505112e+05\n",
       "5     1.0          False    0.0       False -5.505112e+05\n",
       "0     1.0           True    0.0        True -5.012175e+05\n",
       "1     1.0           True    0.0       False -5.012175e+05\n",
       "10    0.0           True    1.0        True -1.467103e+05\n",
       "11    0.0           True    1.0       False -1.467103e+05\n",
       "2     1.0           True    1.0        True -1.467062e+05\n",
       "3     1.0           True    1.0       False -1.467062e+05\n",
       "12    0.0          False    0.0        True -7.723841e+04\n",
       "13    0.0          False    0.0       False -7.723841e+04\n",
       "8     0.0           True    0.0        True -7.387622e+04\n",
       "9     0.0           True    0.0       False -7.387622e+04"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch (X_train_scaled, y_train,TweedieRegressor() , params, 'neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 6 selected feautures based on the the RFE class class are: ['unemployment', 'week_of_year', 'last_year_sales', 'last_week_sales', 'christmas', 'thanksgiving']\n",
      "thanksgiving         1\n",
      "christmas            1\n",
      "unemployment         1\n",
      "week_of_year         1\n",
      "last_week_sales      1\n",
      "last_year_sales      1\n",
      "quarter              2\n",
      "pre_christmas        3\n",
      "store_size           4\n",
      "fuel_price           5\n",
      "year                 6\n",
      "gas_delta_yearly     7\n",
      "holiday_flag         8\n",
      "temperature          9\n",
      "inflation           10\n",
      "super_bowl          11\n",
      "gas_delta_weekly    12\n",
      "labor_day           13\n",
      "tax_season          14\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "top_rfe = select_rfe(X_train_scaled, y_train, 6, TweedieRegressor(alpha =0 , fit_intercept= True, power=0 ,\\\n",
    "                                                                  warm_start= False) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "### select kbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 6 selected feautures based on the SelectKBest class are: ['unemployment', 'store_size', 'last_year_sales', 'last_week_sales', 'pre_christmas', 'thanksgiving']\n"
     ]
    }
   ],
   "source": [
    "#using my function for SelectkBest\n",
    "top_sb =select_kbest(X_train_scaled, y_train, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75736.89572808956"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gml_skb = create_model(X_train_scaled[top_sb], y_train_df, 'actual',TweedieRegressor(alpha =0 , fit_intercept= True, power=0 ,\\\n",
    "                                                                  warm_start= False), 'modelgml' )\n",
    "gml_skb['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74671.92773889692"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gml_rfe = create_model(X_train_scaled[top_rfe], y_train_df, 'actual',TweedieRegressor(alpha =0 , fit_intercept= True, power=0 ,\\\n",
    "                                                                  warm_start= False), 'modelgml' )\n",
    "gml_rfe['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df = metric_df.append(\n",
    "    {\n",
    "    'model': 'gml_rfe',\n",
    "    'rmse_train': gml_rfe['rmse'],    \n",
    "    'r^2' : gml_rfe['r2']}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>rmse_train</th>\n",
       "      <th>r^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean_baseline</td>\n",
       "      <td>563052.730000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ols_rfe</td>\n",
       "      <td>74557.203090</td>\n",
       "      <td>0.982213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lasso_rfe</td>\n",
       "      <td>74486.977411</td>\n",
       "      <td>0.982473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gml_rfe</td>\n",
       "      <td>74671.927739</td>\n",
       "      <td>0.982412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model     rmse_train       r^2\n",
       "0  mean_baseline  563052.730000  0.000000\n",
       "1        ols_rfe   74557.203090  0.982213\n",
       "2      lasso_rfe   74486.977411  0.982473\n",
       "3        gml_rfe   74671.927739  0.982412"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the polynomial features to get a new set of features\n",
    "pf = PolynomialFeatures(degree = 3) \n",
    "\n",
    "# fit and transform X_train_scaled\n",
    "X_train_degree3 = pf.fit_transform(X_train_scaled)\n",
    "\n",
    "# transform X_validate_scaled & X_test_scaled\n",
    "X_test_degree3 = pf.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify the parameters we wish to use as a dictionary, then use that dictionary when we create the class.\n",
    "params = {\n",
    "          'normalize': [True, False],\n",
    "          'fit_intercept':[True, False],\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_intercept</th>\n",
       "      <th>normalize</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-5.396751e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-2.032383e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.784725e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.784725e+14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_intercept  normalize         score\n",
       "0           True       True -5.396751e+15\n",
       "1           True      False -2.032383e+14\n",
       "2          False       True -1.784725e+14\n",
       "3          False      False -1.784725e+14"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch (X_train_degree3, y_train, LinearRegression(normalize=True) , params, 'neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_intercept</th>\n",
       "      <th>normalize</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-3.166867e+20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.796322e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.229404e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.229404e+17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_intercept  normalize         score\n",
       "0           True       True -3.166867e+20\n",
       "1           True      False -1.796322e+17\n",
       "2          False       True -1.229404e+17\n",
       "3          False      False -1.229404e+17"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch (X_train_degree3, y_train, LinearRegression(normalize=True) , params, 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select k best "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 6 selected feautures based on the SelectKBest class are: ['unemployment', 'store_size', 'last_year_sales', 'last_week_sales', 'pre_christmas', 'thanksgiving']\n"
     ]
    }
   ],
   "source": [
    "#using my function for SelectkBest\n",
    "top_sb =select_kbest(X_train_scaled, y_train, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 6 selected feautures based on the the RFE class class are: ['temperature', 'gas_delta_weekly', 'last_year_sales', 'last_week_sales', 'christmas', 'thanksgiving']\n",
      "gas_delta_weekly     1\n",
      "christmas            1\n",
      "last_week_sales      1\n",
      "last_year_sales      1\n",
      "thanksgiving         1\n",
      "temperature          1\n",
      "pre_christmas        2\n",
      "gas_delta_yearly     3\n",
      "year                 4\n",
      "fuel_price           5\n",
      "week_of_year         6\n",
      "super_bowl           7\n",
      "store_size           8\n",
      "labor_day            9\n",
      "holiday_flag        10\n",
      "tax_season          11\n",
      "inflation           12\n",
      "quarter             13\n",
      "unemployment        14\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    " top_rfe = select_rfe(X_train_scaled, y_train, 6, LinearRegression(normalize=False, fit_intercept = False ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41917.93455396443"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pol_rfe = create_model(X_train_degree3, y_train_df, 'actual',LinearRegression( fit_intercept = False ), 'modelpol' )\n",
    "pol_rfe['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df = metric_df.append(\n",
    "    {\n",
    "    'model': 'pol_rfe',\n",
    "    'rmse_train': pol_rfe['rmse'],    \n",
    "    'r^2' : pol_rfe['r2']}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>rmse_train</th>\n",
       "      <th>r^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean_baseline</td>\n",
       "      <td>563052.730000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ols_rfe</td>\n",
       "      <td>74557.203090</td>\n",
       "      <td>0.982213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lasso_rfe</td>\n",
       "      <td>74486.977411</td>\n",
       "      <td>0.982473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gml_rfe</td>\n",
       "      <td>74671.927739</td>\n",
       "      <td>0.982412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pol_rfe</td>\n",
       "      <td>41917.934554</td>\n",
       "      <td>0.992287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model     rmse_train       r^2\n",
       "0  mean_baseline  563052.730000  0.000000\n",
       "1        ols_rfe   74557.203090  0.982213\n",
       "2      lasso_rfe   74486.977411  0.982473\n",
       "3        gml_rfe   74671.927739  0.982412\n",
       "4        pol_rfe   41917.934554  0.992287"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
