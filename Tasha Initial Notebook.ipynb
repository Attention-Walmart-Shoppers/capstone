{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Walmart Shoppers\n",
    "### A Walmart retail analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data was originally retrieved from:\n",
    " -   https://www.kaggle.com/rutuspatel/retail-analysis-with-walmart-sales-data\n",
    " - https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dictionary\n",
    "\n",
    "| Target       |  Data Type       | Description                     |\n",
    "|--------------|------------------|---------------------------------|\n",
    "| Weekly_Sales |   float64        | Sales in USD per week by store  |\n",
    "\n",
    "\n",
    "| Column        |  Data Type       | Description                                      |  \n",
    "|---------------|------------------|--------------------------------------------------|\n",
    "| Store         |     int64        | unique identifier for store  (1-45)              |\n",
    "| Date          |     object       | Date of transaction                              |\n",
    "| Holiday_Flag  |     int64        | indicator of a Holiday week (boolean)            |\n",
    "| Temperature   |     float64      | temperature in Farenheight                       |\n",
    "| Fuel_Price    |     float64      | cost of fuel(in USD) in region                   |\n",
    "| CPI           |     float64      | Prevailing consumer price index, cost of goods   |\n",
    "| Unemployment  |     float64      | Prevailing unemployment rate                     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal:\n",
    "- to predict weekly sales price for a store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Think about...\n",
    "- What is your goal?\n",
    "- what is your TARGET? drivers for that target?\n",
    "- what is one oberservation? what does one row from your dataset represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily meetings\n",
    "- standup doc\n",
    "- shared knowledge doc\n",
    "\n",
    "### Three important Questions\n",
    "- what did you work on since we last talked?\n",
    "- what are you planning on working on next?\n",
    "- what are your blockers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#custom modules\n",
    "import wrangle\n",
    "import new_wrangle\n",
    "\n",
    "#remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bring in walmart data using new_wrangle.py\n",
    "df= new_wrangle.acquire_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a look\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for nulls, dtypes\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the cleaned data using new_wrangle.py\n",
    "df= new_wrangle.wrangle_walmart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure that all columns are created\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a look at the data\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "train, test, X_train, y_train, X_test, y_test = new_wrangle.train_test(df2,'weekly_sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count of season\n",
    "train.season.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counts by holidays\n",
    "train.holiday_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counts by quarter\n",
    "train.quarter.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bivariate exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average weekly sales by store\n",
    "stores = train.groupby(['store_id']).agg({'weekly_sales': ['mean']})\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.bar(stores.index,stores['weekly_sales']['mean'])\n",
    "plt.xticks(np.arange(1, 46, step=1))\n",
    "plt.ylabel('Weekly Sales (in USD)', fontsize=16)\n",
    "plt.xlabel('Store', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize store_type by store_size\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.boxplot(x='store_type', y='store_size', data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways:\n",
    "- Store A: appears to be only larger stores\n",
    "- Store B: appear to be midsized stores\n",
    "- Store C: appears to be only smaller stores\n",
    "\n",
    "- outliers were addressed (store 3, store 5, store 33, store 36 were classified incorrectly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize stores and weekly sales\n",
    "plt.figure(figsize=(14,6))\n",
    "sns.boxplot(x='store_type', y='weekly_sales', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize store type and unemployment rate\n",
    "plt.figure(figsize=(14,6))\n",
    "sns.boxplot(x='store_type', y='unemployment', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('store_id').sales_delta_yearly.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize store type and unemployment rate\n",
    "plt.figure(figsize=(14,6))\n",
    "sns.swarmplot(x='fuel_price', y='temperature', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize store type and unemployment rate\n",
    "plt.figure(figsize=(14,6))\n",
    "sns.swarmplot(x='fuel_price', y='weekly_sales', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize store type and unemployment rate\n",
    "plt.figure(figsize=(14,6))\n",
    "sns.swarmplot(x='week_of_year', y='weekly_sales', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize store type and unemployment rate\n",
    "plt.figure(figsize=(14,6))\n",
    "sns.swarmplot(x='season', y='weekly_sales', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize store type and unemployment rate\n",
    "plt.figure(figsize=(14,6))\n",
    "sns.swarmplot(x='month', y='weekly_sales', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "walmart = train.corr()\n",
    "walmart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this shows correlation with sales\n",
    "wal_corr = walmart['weekly_sales'].sort_values(ascending=False)\n",
    "wal_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 12))\n",
    "heatmap = sns.heatmap(df.corr()[['weekly_sales']].sort_values(by='weekly_sales', ascending=False), vmin=-1, vmax=1, annot=True, cmap='mako_r')\n",
    "heatmap.set_title('Features Correlating with weekly sales', fontdict={'fontsize':18}, pad=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis 1: Pearson's (cont vs cont)\n",
    "$H_0$: There is no correlation between weekly_sales and store_size\n",
    "\n",
    "$H_a$: There is a correlation between weekly_sales and store_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pearsons correlation on entire train set\n",
    "#number of rows\n",
    "n = train.shape[0] \n",
    "\n",
    "#degrees of freedom- how much the data can vary\n",
    "deg_f = n-2 \n",
    "\n",
    "#confidence interval (!)\n",
    "conf_in = 0.95\n",
    "\n",
    "alpha = 1- conf_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= train.weekly_sales\n",
    "y= train.store_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, p = stats.pearsonr(x,y)\n",
    "r,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p < alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'We calculate a pearson r of {r:3f} and a statistical certainty p of {p:4f}')\n",
    "print(f'Because p {p:4f} < α  {alpha:4f}, we can reject our null hypothesis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis 2: Pearson's (cont vs cont)\n",
    "$H_0$: There is no correlation between weekly_sales and temperature\n",
    "\n",
    "$H_a$: There is a correlation between weekly_sales and temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pearsons correlation on entire train set\n",
    "#number of rows\n",
    "n = train.shape[0] \n",
    "\n",
    "#degrees of freedom- how much the data can vary\n",
    "deg_f = n-2 \n",
    "\n",
    "#confidence interval (!)\n",
    "conf_in = 0.95\n",
    "\n",
    "alpha = 1- conf_in\n",
    "\n",
    "x= train.weekly_sales\n",
    "y= train.temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r, p = stats.pearsonr(x,y)\n",
    "r,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p < alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'We calculate a pearson r of {r:3f} and a statistical certainty p of {p:4f}')\n",
    "print(f'Because p {p:4f} < α  {alpha:4f}, we can reject our null hypothesis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis 3: T-Test (cont vs discrete)¶\n",
    "$H_0$: There is no relationship between weekly_sales and week_of_year\n",
    "\n",
    "$H_a$: There is a relationship between weekly_sales and week_of_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set alpha\n",
    "alpha = .05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample size, must be more then 30 to meet assumption\n",
    "train.weekly_sales.count(), train.week_of_year.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check variance\n",
    "train.weekly_sales.var(), train.week_of_year.var()\n",
    "\n",
    "#this shows not equal varient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t-test on entire train set\n",
    "t, p = stats.ttest_ind(train.weekly_sales,train.week_of_year, equal_var=False)\n",
    "t,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p <alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'We calculate a t of {t:3f} and a statistical certainty p of {p:4f}')\n",
    "print(f'Because p {p:4f} < α  {alpha:4f}, we reject our null hypothesis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis 4: Pearson's (cont vs cont)\n",
    "$H_0$: There is no correlation between weekly_sales and last_week_sales\n",
    "\n",
    "$H_a$: There is a correlation between weekly_sales and last_week_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pearsons correlation on entire train set\n",
    "#number of rows\n",
    "n = train.shape[0] \n",
    "\n",
    "#degrees of freedom- how much the data can vary\n",
    "deg_f = n-2 \n",
    "\n",
    "#confidence interval (!)\n",
    "conf_in = 0.95\n",
    "\n",
    "alpha = 1- conf_in\n",
    "\n",
    "x= train.weekly_sales\n",
    "y= train.last_week_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, p = stats.pearsonr(x,y)\n",
    "r,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p < alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'We calculate a pearson r of {r:3f} and a statistical certainty p of {p:4f}')\n",
    "print(f'Because p {p:4f} < α  {alpha:4f}, we can reject our null hypothesis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "- we are clustering in order to attempt to find regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.feature_selection import RFE, SelectKBest, f_regression\n",
    "from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import mean_squared_error, explained_variance_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster 1: CPI & Fuel Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chose variables for this possible cluster\n",
    "X = train[['CPI', 'fuel_price']]\n",
    "#tke a look\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the X\n",
    "scaler = MinMaxScaler().fit(X)\n",
    "X_scaled = pd.DataFrame(scaler.transform(X), columns= X.columns).set_index([X.index.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets plot inertia vs k\n",
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    pd.Series({k: KMeans(k).fit(X_scaled).inertia_ for k in range(2, 12)}).plot(marker='x')\n",
    "    plt.xticks(range(2, 12))\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('inertia')\n",
    "    plt.title('Change in inertia as k increases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_plots(X_scaled, col_name= 'column_one', col_name_two= 'column_two'):\n",
    "    '''\n",
    "    This function takes in two columns and \n",
    "    creates a range of scatter plots based on varying k values\n",
    "    '''\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(10, 10), sharex=True, sharey=True)\n",
    "    for ax, k in zip(axs.ravel(), range(2, 6)):\n",
    "        clusters = KMeans(k).fit(X_scaled).predict(X_scaled)\n",
    "        ax.scatter(X_scaled[col_name], X_scaled[col_name_two], c=clusters)\n",
    "        ax.set(title='k = {}'.format(k), xlabel=col_name, ylabel=col_name_two)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use scatter_plot function \n",
    "#this will show you different clusters with varying k values\n",
    "scatter_plots(X_scaled, col_name= 'CPI', col_name_two= 'fuel_price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster 1 Takeaways\n",
    "- k = 4 appears to show best results\n",
    "- cluster 1 (blue): lower CPI, low fuel prices\n",
    "- cluster 2 (green): high fuel prices, low CPI\n",
    "- cluster 3 (purple): high CPI, low fuel prices\n",
    "- cluster 4 (yellow): high CPI, high fuel prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster 2: CPI & Unemployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chose variables for this possible cluster\n",
    "X2 = train[['CPI', 'unemployment']]\n",
    "#tke a look\n",
    "X2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the X\n",
    "scaler = MinMaxScaler().fit(X2)\n",
    "X2_scaled = pd.DataFrame(scaler.transform(X2), columns= X2.columns).set_index([X2.index.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets plot inertia vs k\n",
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    pd.Series({k: KMeans(k).fit(X2_scaled).inertia_ for k in range(2, 12)}).plot(marker='x')\n",
    "    plt.xticks(range(2, 12))\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('inertia')\n",
    "    plt.title('Change in inertia as k increases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use scatter_plot function \n",
    "#this will show you different clusters with varying k values\n",
    "scatter_plots(X2_scaled, col_name= 'CPI', col_name_two= 'unemployment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster 2 Takeaways\n",
    "- k = 3 appears to show best results\n",
    "- cluster 1 (purple): low unemployment, low cpi\n",
    "- cluster 2 (yellow): high unemployment, low cpi\n",
    "- cluster 3 (teal): high cpi, mid unemployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster 3: Temperature & Unemployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chose variables for this possible cluster\n",
    "X3 = train[['temperature', 'unemployment']]\n",
    "#tke a look\n",
    "X3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the X\n",
    "scaler = MinMaxScaler().fit(X3)\n",
    "X3_scaled = pd.DataFrame(scaler.transform(X3), columns= X3.columns).set_index([X3.index.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets plot inertia vs k\n",
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    pd.Series({k: KMeans(k).fit(X3_scaled).inertia_ for k in range(2, 12)}).plot(marker='x')\n",
    "    plt.xticks(range(2, 12))\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('inertia')\n",
    "    plt.title('Change in inertia as k increases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use scatter_plot function \n",
    "#this will show you different clusters with varying k values\n",
    "scatter_plots(X3_scaled, col_name= 'temperature', col_name_two= 'unemployment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster 3 Takeaways\n",
    "- k = 3 appears to show best results\n",
    "- cluster 1 (green): lower temps, low- mid unemployment\n",
    "- cluster 2 (purple): high temp, low-mid unemployment\n",
    "- cluster 3 (yellow): high unemployment, mid-high temps "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster 4: Temperature & Gas Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chose variables for this possible cluster\n",
    "X4 = train[['temperature', 'fuel_price']]\n",
    "#tke a look\n",
    "X4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the X\n",
    "scaler = MinMaxScaler().fit(X4)\n",
    "X4_scaled = pd.DataFrame(scaler.transform(X4), columns= X4.columns).set_index([X4.index.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets plot inertia vs k\n",
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    pd.Series({k: KMeans(k).fit(X4_scaled).inertia_ for k in range(2, 12)}).plot(marker='x')\n",
    "    plt.xticks(range(2, 12))\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('inertia')\n",
    "    plt.title('Change in inertia as k increases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use scatter_plot function \n",
    "#this will show you different clusters with varying k values\n",
    "scatter_plots(X4_scaled, col_name= 'temperature', col_name_two= 'fuel_price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster 4 Takeaways\n",
    "- k = 4 appears to show best results\n",
    "- cluster 1 (green): lower temps, low fuel prices\n",
    "- cluster 2 (blue): high temp, low fuel prices\n",
    "- cluster 3 (yellow): high fuel prices, low temps \n",
    "- cluster 4 (purple): high temps, high fuel prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need y_train and y_validate to be dataframes to append the new columns with predicted values. \n",
    "y_train = pd.DataFrame({'actual': y_train})\n",
    "y_test = pd.DataFrame({'actual': y_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the baseline\n",
    "baseline= y_train['actual'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create column called baseline to compare\n",
    "y_train['baseline'] = baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate RMSE for baseline model\n",
    "rmse_baseline_train= math.sqrt(mean_squared_error(y_train.actual, y_train.baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe to make data easier to visualize/understand\n",
    "metric_df = pd.DataFrame(data=[{\n",
    "    'model': 'mean_baseline',\n",
    "    'rmse_train': round(rmse_baseline_train, 5)\n",
    "}])\n",
    "\n",
    "metric_df\n",
    "#we now have out baseline model to work off of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RFE\n",
    "## select K Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set features\n",
    "#we do not want to include all columns in this because it could cause overfitting\n",
    "features = ['store_size', 'unemployment', 'week_of_year', 'sales_delta_weekly']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ordinary least squares\n",
    "#create the model \n",
    "model1 = LinearRegression(normalize=True)\n",
    "\n",
    "#fit the model\n",
    "model1.fit(X_train[features], y_train.actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict train\n",
    "y_train['sales_pred_lm'] = model1.predict(X_train[features])\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train = mean_squared_error(y_train.actual, y_train.sales_pred_lm)**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create visual to see baseline vs LinearRegression model\n",
    "metric_df = metric_df.append(\n",
    "    {\n",
    "    'model': 'Model 1: OLS',\n",
    "    'rmse_train': round(rmse_train, 5),\n",
    "    }, ignore_index=True)\n",
    "\n",
    "metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Lars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "model2 = LassoLars(alpha= 2)\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "model2.fit(X_train[features], y_train.actual)\n",
    "\n",
    "# predict train\n",
    "y_train['sales_pred_lars'] = model2.predict(X_train[features])\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train = mean_squared_error(y_train.actual, y_train.sales_pred_lars)**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shows baseline vs LinearRegression vs LassoLars\n",
    "metric_df = metric_df.append(\n",
    "    {\n",
    "    'model': 'Model 2: LassoLars (alpha 2)',\n",
    "    'rmse_train': round(rmse_train,5),\n",
    "    }, ignore_index=True)\n",
    "\n",
    "metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the polynomial features to get a new set of features\n",
    "model3 = PolynomialFeatures(degree=2)\n",
    "\n",
    "# fit and transform X_train_scaled features\n",
    "X_train_degree2 = model3.fit_transform(X_train[features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the model\n",
    "lm2 = LinearRegression(normalize=True)\n",
    "\n",
    "#fit the mode\n",
    "lm2.fit(X_train_degree2, y_train.actual)\n",
    "\n",
    "#use the model\n",
    "y_train['sale_pred_lm2'] = lm2.predict(X_train_degree2)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train_model3 = mean_squared_error(y_train.actual, y_train.sale_pred_lm2) ** (1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shows baseline vs LinearRegression vs LassoLars\n",
    "metric_df = metric_df.append(\n",
    "    {\n",
    "    'model': 'Model 3: Polynomial Regression (degree=2)',\n",
    "    'rmse_train': round(rmse_train_model3,5),\n",
    "    }, ignore_index=True)\n",
    "\n",
    "metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
