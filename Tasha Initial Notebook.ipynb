{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Walmart Shoppers\n",
    "### A Walmart retail analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data was originally retrieved from:\n",
    " -   https://www.kaggle.com/rutuspatel/retail-analysis-with-walmart-sales-data\n",
    " - https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dictionary\n",
    "\n",
    "| Target       |  Data Type       | Description                     |\n",
    "|--------------|------------------|---------------------------------|\n",
    "| Weekly_Sales |   float64        | Sales in USD per week by store  |\n",
    "\n",
    "\n",
    "| Column        |  Data Type       | Description                                      |  \n",
    "|---------------|------------------|--------------------------------------------------|\n",
    "| Store         |     int64        | unique identifier for store  (1-45)              |\n",
    "| Date          |     object       | Date of transaction                              |\n",
    "| Holiday_Flag  |     int64        | indicator of a Holiday week (boolean)            |\n",
    "| Temperature   |     float64      | temperature in Farenheight                       |\n",
    "| Fuel_Price    |     float64      | cost of fuel(in USD) in region                   |\n",
    "| CPI           |     float64      | Prevailing consumer price index, cost of goods   |\n",
    "| Unemployment  |     float64      | Prevailing unemployment rate                     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal:\n",
    "- to predict weekly sales price for a store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Think about...\n",
    "- What is your goal?\n",
    "- what is your TARGET? drivers for that target?\n",
    "- what is one oberservation? what does one row from your dataset represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily meetings\n",
    "- standup doc\n",
    "- shared knowledge doc\n",
    "\n",
    "### Three important Questions\n",
    "- what did you work on since we last talked?\n",
    "- what are you planning on working on next?\n",
    "- what are your blockers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#custom modules\n",
    "import wrangle\n",
    "import new_wrangle\n",
    "\n",
    "#remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bring in walmart data using new_wrangle.py\n",
    "df= new_wrangle.acquire_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Date</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Holiday_Flag</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>05-02-2010</td>\n",
       "      <td>1643690.90</td>\n",
       "      <td>0</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>12-02-2010</td>\n",
       "      <td>1641957.44</td>\n",
       "      <td>1</td>\n",
       "      <td>38.51</td>\n",
       "      <td>2.548</td>\n",
       "      <td>211.242170</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19-02-2010</td>\n",
       "      <td>1611968.17</td>\n",
       "      <td>0</td>\n",
       "      <td>39.93</td>\n",
       "      <td>2.514</td>\n",
       "      <td>211.289143</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>26-02-2010</td>\n",
       "      <td>1409727.59</td>\n",
       "      <td>0</td>\n",
       "      <td>46.63</td>\n",
       "      <td>2.561</td>\n",
       "      <td>211.319643</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>05-03-2010</td>\n",
       "      <td>1554806.68</td>\n",
       "      <td>0</td>\n",
       "      <td>46.50</td>\n",
       "      <td>2.625</td>\n",
       "      <td>211.350143</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store        Date  Weekly_Sales  Holiday_Flag  Temperature  Fuel_Price  \\\n",
       "0      1  05-02-2010    1643690.90             0        42.31       2.572   \n",
       "1      1  12-02-2010    1641957.44             1        38.51       2.548   \n",
       "2      1  19-02-2010    1611968.17             0        39.93       2.514   \n",
       "3      1  26-02-2010    1409727.59             0        46.63       2.561   \n",
       "4      1  05-03-2010    1554806.68             0        46.50       2.625   \n",
       "\n",
       "          CPI  Unemployment Type    Size  \n",
       "0  211.096358         8.106    A  151315  \n",
       "1  211.242170         8.106    A  151315  \n",
       "2  211.289143         8.106    A  151315  \n",
       "3  211.319643         8.106    A  151315  \n",
       "4  211.350143         8.106    A  151315  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take a look\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6435 entries, 0 to 6434\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Store         6435 non-null   int64  \n",
      " 1   Date          6435 non-null   object \n",
      " 2   Weekly_Sales  6435 non-null   float64\n",
      " 3   Holiday_Flag  6435 non-null   int64  \n",
      " 4   Temperature   6435 non-null   float64\n",
      " 5   Fuel_Price    6435 non-null   float64\n",
      " 6   CPI           6435 non-null   float64\n",
      " 7   Unemployment  6435 non-null   float64\n",
      " 8   Type          6435 non-null   object \n",
      " 9   Size          6435 non-null   int64  \n",
      "dtypes: float64(5), int64(3), object(2)\n",
      "memory usage: 553.0+ KB\n"
     ]
    }
   ],
   "source": [
    "#check for nulls, dtypes\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the cleaned data using new_wrangle.py\n",
    "df= new_wrangle.wrangle_walmart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 6435 entries, 2010-02-05 to 2012-10-26\n",
      "Data columns (total 21 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   store_id            6435 non-null   object \n",
      " 1   weekly_sales        6435 non-null   float64\n",
      " 2   holiday_flag        6435 non-null   int64  \n",
      " 3   temperature         6435 non-null   int64  \n",
      " 4   fuel_price          6435 non-null   float64\n",
      " 5   CPI                 6435 non-null   float64\n",
      " 6   unemployment        6435 non-null   float64\n",
      " 7   store_type          6435 non-null   object \n",
      " 8   store_size          6435 non-null   int64  \n",
      " 9   month               6435 non-null   object \n",
      " 10  year                6435 non-null   int64  \n",
      " 11  quarter             6435 non-null   int64  \n",
      " 12  weekday             6435 non-null   object \n",
      " 13  week_of_year        6435 non-null   int64  \n",
      " 14  deflated_series     6435 non-null   float64\n",
      " 15  sales_delta_weekly  6435 non-null   float64\n",
      " 16  sales_delta_yearly  6435 non-null   float64\n",
      " 17  gas_delta_weekly    6435 non-null   float64\n",
      " 18  gas_delta_yearly    6435 non-null   float64\n",
      " 19  season              6435 non-null   object \n",
      " 20  holiday_name        6435 non-null   object \n",
      "dtypes: float64(9), int64(6), object(6)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#make sure that all columns are created\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>weekly_sales</th>\n",
       "      <th>holiday_flag</th>\n",
       "      <th>temperature</th>\n",
       "      <th>fuel_price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>unemployment</th>\n",
       "      <th>store_type</th>\n",
       "      <th>store_size</th>\n",
       "      <th>month</th>\n",
       "      <th>...</th>\n",
       "      <th>quarter</th>\n",
       "      <th>weekday</th>\n",
       "      <th>week_of_year</th>\n",
       "      <th>deflated_series</th>\n",
       "      <th>sales_delta_weekly</th>\n",
       "      <th>sales_delta_yearly</th>\n",
       "      <th>gas_delta_weekly</th>\n",
       "      <th>gas_delta_yearly</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-10-26</th>\n",
       "      <td>25</td>\n",
       "      <td>688940.94</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>3.88</td>\n",
       "      <td>216.152</td>\n",
       "      <td>7.293</td>\n",
       "      <td>B</td>\n",
       "      <td>128107</td>\n",
       "      <td>October</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>Friday</td>\n",
       "      <td>43</td>\n",
       "      <td>3187.30</td>\n",
       "      <td>3409.09</td>\n",
       "      <td>-35503.03</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.31</td>\n",
       "      <td>Fall</td>\n",
       "      <td>no_holiday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-26</th>\n",
       "      <td>5</td>\n",
       "      <td>319550.77</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>3.51</td>\n",
       "      <td>224.038</td>\n",
       "      <td>5.422</td>\n",
       "      <td>B</td>\n",
       "      <td>34875</td>\n",
       "      <td>October</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>Friday</td>\n",
       "      <td>43</td>\n",
       "      <td>1426.32</td>\n",
       "      <td>6192.62</td>\n",
       "      <td>12515.66</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.14</td>\n",
       "      <td>Fall</td>\n",
       "      <td>no_holiday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-26</th>\n",
       "      <td>40</td>\n",
       "      <td>921264.52</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>3.92</td>\n",
       "      <td>138.728</td>\n",
       "      <td>4.145</td>\n",
       "      <td>A</td>\n",
       "      <td>155083</td>\n",
       "      <td>October</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>Friday</td>\n",
       "      <td>43</td>\n",
       "      <td>6640.80</td>\n",
       "      <td>3094.02</td>\n",
       "      <td>-20411.43</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.32</td>\n",
       "      <td>Fall</td>\n",
       "      <td>no_holiday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-26</th>\n",
       "      <td>18</td>\n",
       "      <td>1127516.25</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>3.92</td>\n",
       "      <td>138.728</td>\n",
       "      <td>8.243</td>\n",
       "      <td>B</td>\n",
       "      <td>120653</td>\n",
       "      <td>October</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>Friday</td>\n",
       "      <td>43</td>\n",
       "      <td>8127.53</td>\n",
       "      <td>78809.50</td>\n",
       "      <td>20873.62</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.32</td>\n",
       "      <td>Fall</td>\n",
       "      <td>no_holiday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-26</th>\n",
       "      <td>45</td>\n",
       "      <td>760281.43</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>3.88</td>\n",
       "      <td>192.309</td>\n",
       "      <td>8.667</td>\n",
       "      <td>B</td>\n",
       "      <td>118221</td>\n",
       "      <td>October</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>Friday</td>\n",
       "      <td>43</td>\n",
       "      <td>3953.44</td>\n",
       "      <td>42155.90</td>\n",
       "      <td>-21413.14</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.31</td>\n",
       "      <td>Fall</td>\n",
       "      <td>no_holiday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           store_id  weekly_sales  holiday_flag  temperature  fuel_price  \\\n",
       "Date                                                                       \n",
       "2012-10-26       25     688940.94             0           56        3.88   \n",
       "2012-10-26        5     319550.77             0           71        3.51   \n",
       "2012-10-26       40     921264.52             0           49        3.92   \n",
       "2012-10-26       18    1127516.25             0           56        3.92   \n",
       "2012-10-26       45     760281.43             0           58        3.88   \n",
       "\n",
       "                CPI  unemployment store_type  store_size    month  ...  \\\n",
       "Date                                                               ...   \n",
       "2012-10-26  216.152         7.293          B      128107  October  ...   \n",
       "2012-10-26  224.038         5.422          B       34875  October  ...   \n",
       "2012-10-26  138.728         4.145          A      155083  October  ...   \n",
       "2012-10-26  138.728         8.243          B      120653  October  ...   \n",
       "2012-10-26  192.309         8.667          B      118221  October  ...   \n",
       "\n",
       "            quarter  weekday week_of_year  deflated_series  \\\n",
       "Date                                                         \n",
       "2012-10-26        4   Friday           43          3187.30   \n",
       "2012-10-26        4   Friday           43          1426.32   \n",
       "2012-10-26        4   Friday           43          6640.80   \n",
       "2012-10-26        4   Friday           43          8127.53   \n",
       "2012-10-26        4   Friday           43          3953.44   \n",
       "\n",
       "            sales_delta_weekly  sales_delta_yearly  gas_delta_weekly  \\\n",
       "Date                                                                   \n",
       "2012-10-26             3409.09           -35503.03             -0.09   \n",
       "2012-10-26             6192.62            12515.66             -0.08   \n",
       "2012-10-26             3094.02           -20411.43             -0.08   \n",
       "2012-10-26            78809.50            20873.62             -0.08   \n",
       "2012-10-26            42155.90           -21413.14             -0.09   \n",
       "\n",
       "            gas_delta_yearly  season holiday_name  \n",
       "Date                                               \n",
       "2012-10-26              0.31    Fall   no_holiday  \n",
       "2012-10-26              0.14    Fall   no_holiday  \n",
       "2012-10-26              0.32    Fall   no_holiday  \n",
       "2012-10-26              0.32    Fall   no_holiday  \n",
       "2012-10-26              0.31    Fall   no_holiday  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take a look at the data\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sales from last year\n",
    "df['last_year_sales'] = df.groupby('store_id').weekly_sales.shift(-52)\n",
    "#sales for last week\n",
    "df['last_week_sales'] = df.groupby('store_id').weekly_sales.shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'drop'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3a71c25379fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#train test split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_wrangle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'weekly_sales'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/codeup-data-science/database-exercises/capstone/new_wrangle.py\u001b[0m in \u001b[0;36mtrain_test\u001b[0;34m(df, target)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;31m# split test into X (dataframe, drop target) & y (series, keep target only)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m     \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m     \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'drop'"
     ]
    }
   ],
   "source": [
    "#train test split\n",
    "train, test, X_train, y_train, X_test, y_test = new_wrangle.train_test(df,'weekly_sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count of season\n",
    "train.season.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counts by holidays\n",
    "train.holiday_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counts by quarter\n",
    "train.quarter.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bivariate exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average weekly sales by store\n",
    "stores = train.groupby(['store_id']).agg({'weekly_sales': ['mean']})\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.bar(stores.index,stores['weekly_sales']['mean'])\n",
    "plt.xticks(np.arange(1, 46, step=1))\n",
    "plt.ylabel('Weekly Sales (in USD)', fontsize=16)\n",
    "plt.xlabel('Store', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize store_type by store_size\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.boxplot(x='store_type', y='store_size', data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways:\n",
    "- Store A: appears to be only larger stores\n",
    "- Store B: appear to be midsized stores\n",
    "- Store C: appears to be only smaller stores\n",
    "\n",
    "- outliers were addressed (store 3, store 5, store 33, store 36 were classified incorrectly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize stores and weekly sales\n",
    "plt.figure(figsize=(14,6))\n",
    "sns.boxplot(x='store_type', y='weekly_sales', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize store type and unemployment rate\n",
    "plt.figure(figsize=(14,6))\n",
    "sns.boxplot(x='store_type', y='unemployment', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('store_id').sales_delta_yearly.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize store type and unemployment rate\n",
    "plt.figure(figsize=(14,6))\n",
    "sns.swarmplot(x='fuel_price', y='temperature', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize store type and unemployment rate\n",
    "plt.figure(figsize=(14,6))\n",
    "sns.swarmplot(x='fuel_price', y='weekly_sales', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize store type and unemployment rate\n",
    "plt.figure(figsize=(14,6))\n",
    "sns.swarmplot(x='week_of_year', y='weekly_sales', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize store type and unemployment rate\n",
    "plt.figure(figsize=(14,6))\n",
    "sns.swarmplot(x='season', y='weekly_sales', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize store type and unemployment rate\n",
    "plt.figure(figsize=(14,6))\n",
    "sns.swarmplot(x='month', y='weekly_sales', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "walmart = train.corr()\n",
    "walmart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this shows correlation with sales\n",
    "wal_corr = walmart['weekly_sales'].sort_values(ascending=False)\n",
    "wal_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 12))\n",
    "heatmap = sns.heatmap(df.corr()[['weekly_sales']].sort_values(by='weekly_sales', ascending=False), vmin=-1, vmax=1, annot=True, cmap='mako_r')\n",
    "heatmap.set_title('Features Correlating with weekly sales', fontdict={'fontsize':18}, pad=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis 1: Pearson's (cont vs cont)\n",
    "$H_0$: There is no correlation between weekly_sales and store_size\n",
    "\n",
    "$H_a$: There is a correlation between weekly_sales and store_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pearsons correlation on entire train set\n",
    "#number of rows\n",
    "n = train.shape[0] \n",
    "\n",
    "#degrees of freedom- how much the data can vary\n",
    "deg_f = n-2 \n",
    "\n",
    "#confidence interval (!)\n",
    "conf_in = 0.95\n",
    "\n",
    "alpha = 1- conf_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= train.weekly_sales\n",
    "y= train.store_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, p = stats.pearsonr(x,y)\n",
    "r,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p < alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'We calculate a pearson r of {r:3f} and a statistical certainty p of {p:4f}')\n",
    "print(f'Because p {p:4f} < α  {alpha:4f}, we can reject our null hypothesis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis 2: Pearson's (cont vs cont)\n",
    "$H_0$: There is no correlation between weekly_sales and temperature\n",
    "\n",
    "$H_a$: There is a correlation between weekly_sales and temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pearsons correlation on entire train set\n",
    "#number of rows\n",
    "n = train.shape[0] \n",
    "\n",
    "#degrees of freedom- how much the data can vary\n",
    "deg_f = n-2 \n",
    "\n",
    "#confidence interval (!)\n",
    "conf_in = 0.95\n",
    "\n",
    "alpha = 1- conf_in\n",
    "\n",
    "x= train.weekly_sales\n",
    "y= train.temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, p = stats.pearsonr(x,y)\n",
    "r,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p < alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'We calculate a pearson r of {r:3f} and a statistical certainty p of {p:4f}')\n",
    "print(f'Because p {p:4f} < α  {alpha:4f}, we can reject our null hypothesis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis 3: T-Test (cont vs discrete)¶\n",
    "$H_0$: There is no relationship between weekly_sales and week_of_year\n",
    "\n",
    "$H_a$: There is a relationship between weekly_sales and week_of_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set alpha\n",
    "alpha = .05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample size, must be more then 30 to meet assumption\n",
    "train.weekly_sales.count(), train.week_of_year.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check variance\n",
    "train.weekly_sales.var(), train.week_of_year.var()\n",
    "\n",
    "#this shows not equal varient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t-test on entire train set\n",
    "t, p = stats.ttest_ind(train.weekly_sales,train.week_of_year, equal_var=False)\n",
    "t,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p <alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'We calculate a t of {t:3f} and a statistical certainty p of {p:4f}')\n",
    "print(f'Because p {p:4f} < α  {alpha:4f}, we reject our null hypothesis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "- we are clustering in order to attempt to find regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.feature_selection import RFE, SelectKBest, f_regression\n",
    "from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import mean_squared_error, explained_variance_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster 1: CPI & Fuel Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chose variables for this possible cluster\n",
    "X = train[['CPI', 'fuel_price']]\n",
    "#tke a look\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the X\n",
    "scaler = MinMaxScaler().fit(X)\n",
    "X_scaled = pd.DataFrame(scaler.transform(X), columns= X.columns).set_index([X.index.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets plot inertia vs k\n",
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    pd.Series({k: KMeans(k).fit(X_scaled).inertia_ for k in range(2, 12)}).plot(marker='x')\n",
    "    plt.xticks(range(2, 12))\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('inertia')\n",
    "    plt.title('Change in inertia as k increases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_plots(X_scaled, col_name= 'column_one', col_name_two= 'column_two'):\n",
    "    '''\n",
    "    This function takes in two columns and \n",
    "    creates a range of scatter plots based on varying k values\n",
    "    '''\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(10, 10), sharex=True, sharey=True)\n",
    "    for ax, k in zip(axs.ravel(), range(2, 6)):\n",
    "        clusters = KMeans(k).fit(X_scaled).predict(X_scaled)\n",
    "        ax.scatter(X_scaled[col_name], X_scaled[col_name_two], c=clusters)\n",
    "        ax.set(title='k = {}'.format(k), xlabel=col_name, ylabel=col_name_two)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use scatter_plot function \n",
    "#this will show you different clusters with varying k values\n",
    "scatter_plots(X_scaled, col_name= 'CPI', col_name_two= 'fuel_price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster 2: CPI & Unemployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chose variables for this possible cluster\n",
    "X2 = train[['CPI', 'unemployment']]\n",
    "#tke a look\n",
    "X2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the X\n",
    "scaler = MinMaxScaler().fit(X2)\n",
    "X2_scaled = pd.DataFrame(scaler.transform(X2), columns= X2.columns).set_index([X2.index.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets plot inertia vs k\n",
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    pd.Series({k: KMeans(k).fit(X2_scaled).inertia_ for k in range(2, 12)}).plot(marker='x')\n",
    "    plt.xticks(range(2, 12))\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('inertia')\n",
    "    plt.title('Change in inertia as k increases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use scatter_plot function \n",
    "#this will show you different clusters with varying k values\n",
    "scatter_plots(X2_scaled, col_name= 'CPI', col_name_two= 'unemployment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster 3: Temperature & Unemployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chose variables for this possible cluster\n",
    "X3 = train[['temperature', 'unemployment']]\n",
    "#tke a look\n",
    "X3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the X\n",
    "scaler = MinMaxScaler().fit(X3)\n",
    "X3_scaled = pd.DataFrame(scaler.transform(X3), columns= X3.columns).set_index([X3.index.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets plot inertia vs k\n",
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    pd.Series({k: KMeans(k).fit(X3_scaled).inertia_ for k in range(2, 12)}).plot(marker='x')\n",
    "    plt.xticks(range(2, 12))\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('inertia')\n",
    "    plt.title('Change in inertia as k increases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use scatter_plot function \n",
    "#this will show you different clusters with varying k values\n",
    "scatter_plots(X3_scaled, col_name= 'temperature', col_name_two= 'unemployment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster 4: Temperature & Gas Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chose variables for this possible cluster\n",
    "X4 = train[['temperature', 'fuel_price']]\n",
    "#tke a look\n",
    "X4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the X\n",
    "scaler = MinMaxScaler().fit(X4)\n",
    "X4_scaled = pd.DataFrame(scaler.transform(X4), columns= X4.columns).set_index([X4.index.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets plot inertia vs k\n",
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    pd.Series({k: KMeans(k).fit(X4_scaled).inertia_ for k in range(2, 12)}).plot(marker='x')\n",
    "    plt.xticks(range(2, 12))\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('inertia')\n",
    "    plt.title('Change in inertia as k increases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use scatter_plot function \n",
    "#this will show you different clusters with varying k values\n",
    "scatter_plots(X4_scaled, col_name= 'temperature', col_name_two= 'fuel_price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need y_train and y_validate to be dataframes to append the new columns with predicted values. \n",
    "y_train = pd.DataFrame({'actual': y_train})\n",
    "y_test = pd.DataFrame({'actual': y_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the baseline\n",
    "baseline= y_train['actual'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create column called baseline to compare\n",
    "y_train['baseline'] = baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate RMSE for baseline model\n",
    "rmse_baseline_train= math.sqrt(mean_squared_error(y_train.actual, y_train.baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe to make data easier to visualize/understand\n",
    "metric_df = pd.DataFrame(data=[{\n",
    "    'model': 'mean_baseline',\n",
    "    'rmse_train': round(rmse_baseline_train, 5)\n",
    "}])\n",
    "\n",
    "metric_df\n",
    "#we now have out baseline model to work off of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RFE\n",
    "## select K Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set features\n",
    "#we do not want to include all columns in this because it could cause overfitting\n",
    "features = ['store_size', 'unemployment', 'week_of_year', 'sales_delta_weekly']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ordinary least squares\n",
    "#create the model \n",
    "model1 = LinearRegression(normalize=True)\n",
    "\n",
    "#fit the model\n",
    "model1.fit(X_train[features], y_train.actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict train\n",
    "y_train['sales_pred_lm'] = model1.predict(X_train[features])\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train = mean_squared_error(y_train.actual, y_train.sales_pred_lm)**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create visual to see baseline vs LinearRegression model\n",
    "metric_df = metric_df.append(\n",
    "    {\n",
    "    'model': 'Model 1: OLS',\n",
    "    'rmse_train': round(rmse_train, 5),\n",
    "    }, ignore_index=True)\n",
    "\n",
    "metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Lars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "model2 = LassoLars(alpha= 2)\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "model2.fit(X_train[features], y_train.actual)\n",
    "\n",
    "# predict train\n",
    "y_train['sales_pred_lars'] = model2.predict(X_train[features])\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train = mean_squared_error(y_train.actual, y_train.sales_pred_lars)**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shows baseline vs LinearRegression vs LassoLars\n",
    "metric_df = metric_df.append(\n",
    "    {\n",
    "    'model': 'Model 2: LassoLars (alpha 2)',\n",
    "    'rmse_train': round(rmse_train,5),\n",
    "    }, ignore_index=True)\n",
    "\n",
    "metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the polynomial features to get a new set of features\n",
    "model3 = PolynomialFeatures(degree=2)\n",
    "\n",
    "# fit and transform X_train_scaled features\n",
    "X_train_degree2 = model3.fit_transform(X_train[features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the model\n",
    "lm2 = LinearRegression(normalize=True)\n",
    "\n",
    "#fit the mode\n",
    "lm2.fit(X_train_degree2, y_train.actual)\n",
    "\n",
    "#use the model\n",
    "y_train['sale_pred_lm2'] = lm2.predict(X_train_degree2)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train_model3 = mean_squared_error(y_train.actual, y_train.sale_pred_lm2) ** (1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shows baseline vs LinearRegression vs LassoLars\n",
    "metric_df = metric_df.append(\n",
    "    {\n",
    "    'model': 'Model 3: Polynomial Regression (degree=2)',\n",
    "    'rmse_train': round(rmse_train_model3,5),\n",
    "    }, ignore_index=True)\n",
    "\n",
    "metric_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
