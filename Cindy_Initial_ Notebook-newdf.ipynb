{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import wrangle\n",
    "import new_wrangle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# acquire data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic acquire data, we are not modifying anything. We just wan to see the data ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use function to acquire data\n",
    "df1= wrangle.acquire_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check  info\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1= new_wrangle.change_columns(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = new_wrangle.this_week_next_week_lagger(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = new_wrangle.add_which_holiday(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 =new_wrangle.add_which_holiday(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = new_wrangle.create_dummies(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = new_wrangle.get_new_index(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_delta(df):\n",
    "    \n",
    "    '''\n",
    "    This function will calculate rolling monthly averages for CPI, f\n",
    "    fuel_price & Unemployment and reference these rolling avgs on weekly periods to calculate a MoM % change.\n",
    "    NOTE: Due to our modified index, the initial calcs for each store reference prvs store end data due to sequencing.\n",
    "    This issue is resolved 8 periods into the time series for each store when enough data for new store is in place. \n",
    "    '''\n",
    "    \n",
    "    # calc monthly rolling avgs for each feature\n",
    "    df['fuel_4wk_rolling'] = df.fuel_price.rolling(4).mean()\n",
    "    df['cpi_4wk_rolling'] = df.CPI.rolling(4).mean()\n",
    "    df['unemp_4wk_rolling'] = df.this_week_unemployment.rolling(4).mean()\n",
    "    \n",
    "    # calc percent month-on-month delta on weekly monthly avg observation\n",
    "    df['avgMoM_perc_fuel'] = df.fuel_4wk_rolling.pct_change(4)\n",
    "    df['avgMoM_perc_cpi'] = df.cpi_4wk_rolling.pct_change(4)\n",
    "    df['avgMoM_perc_unemp'] = df.unemp_4wk_rolling.pct_change(4)\n",
    "    \n",
    "    # calc quarterly rolling avgs for each feature\n",
    "    df['fuel_quarterly_rolling'] = df.fuel_price.rolling(12).mean()\n",
    "    df['cpi_quarterly_rolling'] = df.CPI.rolling(12).mean()\n",
    "    df['unemp_quarterly_rolling'] = df.this_week_unemployment.rolling(12).mean()\n",
    "    \n",
    "    # calc percent quarter-on-quarter delta on weekly monthly avg observation\n",
    "    df['avgQoQ_perc_fuel'] = df.fuel_quarterly_rolling.pct_change(12)\n",
    "    df['avgQoQ_perc_cpi'] = df.cpi_quarterly_rolling.pct_change(12)\n",
    "    df['avgQoQ_perc_unemp'] = df.unemp_quarterly_rolling.pct_change(12)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = rolling_delta(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df5.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df5.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test,  X_train_scaled, X_test_scaled, y_train, y_test =new_wrangle.split_scale(df5, 'next_week_sales_target', MinMaxScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season(now_date):\n",
    "    '''\n",
    "    This function gets the season from a dateteime\n",
    "    '''\n",
    "    \n",
    "    Y = 2000 # dummy leap year to allow input X-02-29 (leap day)\n",
    "    seasons = [('winter', '2000-01-01',  '2000-03-01'),\n",
    "           ('spring', '2000-03-21',  '2000-06-20'),\n",
    "           ('summer', '2000-06-21',  '2000-09-22'),\n",
    "           ('fall', '2000-09-23',  '2000-12-20'),\n",
    "           ('winter', '2000-12-21',  '2000-12-31')]\n",
    "        \n",
    "    now = now_date.replace(year, Y)\n",
    "    \n",
    "    season = next(season for season, (start, end) in seasons if start <= now <= end)\n",
    "    \n",
    "    return season\n",
    "\n",
    "\n",
    "def season_column(df):\n",
    "    '''\n",
    "    This function creates two new columns \n",
    "    Season for this week date \n",
    "    And season for next week date\n",
    "    Uses get_season function\n",
    "    '''\n",
    "\n",
    "    df['next_week_season'] = df.dropna().next_week_date.apply(get_season)\n",
    "\n",
    "    df['this_week_season'] = df.dropna().this_week_date.apply(get_season)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(df.this_week_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p = ['next_week_date'].astype('string')[0][5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l=[]\n",
    "# for r in range (len (df1)):\n",
    "#    fp= df1['next_week_date'].astype('string')[r][5:]\n",
    "#     da= '2020'+ fp\n",
    "    l= l+ da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_season(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways**\n",
    "- we have 10 columns and 6435 columns\n",
    "- no nulls\n",
    "- we nned to change some columns type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ouliers store_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are exploring the store_type vs store_size, we notice that there are outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x= df1['Type'], y= df1['Size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check only the outliers\n",
    "sns.boxplot(x= df1['Type'], y= df1['Size'])\n",
    "plt.ylim(0,46000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see there are outliers for B and A and we decided to change those to  store type C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting a df that has all store_size < 50000 and df.store_type != \"C\"\n",
    "df3 = df1 [(df1.Size < 50000) & (df1.Type != \"C\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets see which stores type A  are df.store_size < 50000\n",
    "df3[df3.Type == \"A\"].groupby('Store').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#lets see which stores type A  are df.store_size < 50000\n",
    "df3[df3.Type == \"B\"].groupby('Store').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways**\n",
    "- Instead of removing theses outliers, we decided to change them to the type based on the size.\n",
    "- I gave the store_id to Natasha so she is going to change the type in the wrangle function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the wrangle_walmar function is renaming columns, adding new columns, dummi variables, and set date as index (datetime type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#using the funcion wrangle\n",
    "df= new_wrangle.wrangle_walmart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#chec the data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#checking if the store_type has no outliers\n",
    "sns.boxplot(x= df['store_type'], y= df['store_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.select_dtypes(exclude = ['datetime64[ns]', 'object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribution (df):\n",
    "    '''\n",
    "    takes in a df and plot individual variable distributions excluding object type\n",
    "    '''\n",
    "    plt.figure\n",
    "    plt.style.use(\"ggplot\")\n",
    "    df2 = df.select_dtypes(exclude = ['datetime64[ns]', 'object'])\n",
    "    cols =df2.columns.to_list()\n",
    "    for col in cols:\n",
    "\n",
    "        plt.hist(df[col],color ='blue')\n",
    "        plt.title(f'Distribution of {col}')\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel('Number of Weeks ')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.ticklabel_format(style = 'plain')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "distribution(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('store_type').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#let see distribution by store type\n",
    "store_type = [\"A\", \"B\", \"C\"]\n",
    "for store in store_type:\n",
    "    print(\"Store type: \", store)\n",
    "    distribution(df[df.store_type == store])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#how many stores are Type C\n",
    "len(df[df.store_type == 'C'].store_id.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storeid for type c\n",
    "df[df.store_type == 'C'].store_size.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#store if for type B\n",
    "df[df.store_type == 'B'].store_size.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many stores are Type B\n",
    "len(df[df.store_type == 'B'].store_id.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store_Id for type A\n",
    "df[df.store_type == 'A'].store_size.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##how many stores are Type A\n",
    "len(df[df.store_type == 'A'].store_id.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways**\n",
    "- after wrangle_walmar we ended with 17 columns, and 6435 observations ( we have nulls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid blue\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the following steps were done to complete the wrangle function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dummies "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we are going to create dummies for :\n",
    "- Holiday_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dummy variables for 5 columns\n",
    "def create_multiple_dummies (df, dumm_col = ['holiday_name', 'season', 'store_type', 'month', 'year']):\n",
    "    '''\n",
    "    Takes in a df and columns to create dummies.\n",
    "    retunr the original df with de new columns (dimmies)\n",
    "    '''\n",
    "    #the column year is an integer we need to conver as string\n",
    "    df['year']= df['year'].astype('string')\n",
    "    #create dummy variables \n",
    "    for col in dumm_col:\n",
    "        #create dummies\n",
    "        df_dummies = pd.get_dummies(df[col], dummy_na=False)\n",
    "        #  concat df_dummies with my df\n",
    "        df = pd.concat([df, df_dummies], axis =1)\n",
    "    #drop no_holiday columns and year\n",
    "    df = df.drop(columns = ['no_holiday', 'year'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummies (df, dumm_col = ['holiday_name']):\n",
    "    '''\n",
    "    Takes in a df and columns to create dummies.\n",
    "    retunr the original df with de new columns (dummies)\n",
    "    '''\n",
    "    #create dummy variables \n",
    "    for col in dumm_col:\n",
    "        #create dummies\n",
    "        df_dummies = pd.get_dummies(df[col], dummy_na=False)\n",
    "        #  concat df_dummies with my df\n",
    "        df = pd.concat([df, df_dummies], axis =1)\n",
    "    #drop no_holiday columns and year\n",
    "    df = df.drop(columns = ['no_holiday'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['holiday_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the function before I add it to .py file\n",
    "df2 = create_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#we need to create new columns  pre- christmas  and tax_season because on exploration(Alberto and Heather ) they found a peak in those dates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the previous weeks for christmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df2.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a new column for is pre_christmas\n",
    "\n",
    "-Christmas:\n",
    "\n",
    "    - 31-Dec-10,  (pre_christmas = 24-Dec-10, 17-Dec 10)\n",
    "    - 30-Dec-11, (pre_christmas = 23-Dec-11, 16-Dec 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new colum and add zeros to everything\n",
    "df2 ['pre_christmas'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the list for pre_christmas\n",
    "pre_c= ['2010-12-24', '2010-12-17', '2011-12-23', '2011-12-16']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add value 1 for only pre_christmas weeks\n",
    "#df2.loc[pre_c, 'pre_christmas'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK THE VALUES\n",
    "#df2['pre_christmas'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ADD TAX SEASON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  first 2 weeks of April\n",
    "- 2010-04-02 & 2010-04-09\n",
    "- 2011-04-01 & 2011-04-08\n",
    "- 2012-04-06 & 2012-04-13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crete a new column and assign 0 as value\n",
    "df2['tax_season'] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the list for tax\n",
    "tax= ['2010-04-02 ', '2010-04-09', '2011-04-01', '2011-04-08', '2012-04-06', '2012-04-13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add value 1 for only for the list above\n",
    "df2.loc[tax, 'tax_season'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK THE VALUES\n",
    "df2['tax_season'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**note :** before scaling we need to split our data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select only the numeric columns \n",
    "num_df = df2.select_dtypes(exclude='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split using a function\n",
    "train, test, X_train, y_train, X_test, y_test = new_wrangle.train_test(num_df, 'weekly_sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports to scale\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_df ( train_df , test_df, columns,  scaler):\n",
    "    '''\n",
    "    Take in a 3 df and a type of scaler that you  want to  use. it will scale all columns\n",
    "    except object type. Fit a scaler only in train and tramnsform in train, validate and test.\n",
    "    returns  new dfs with the scaled columns.\n",
    "    scaler : MinMaxScaler() or RobustScaler(), StandardScaler() \n",
    "    Example:\n",
    "    scaled_df( X_train , X_test, columns , RobustScaler())\n",
    "    \n",
    "    '''\n",
    "    #import\n",
    "    from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "    # fit our scaler\n",
    "    scaler.fit(train_df[columns])\n",
    "    # get our scaled arrays\n",
    "    train_scaled = scaler.transform(train_df[columns])\n",
    "    test_scaled= scaler.transform(test_df[columns])\n",
    "\n",
    "    # convert arrays to dataframes\n",
    "    train_scaled_df = pd.DataFrame(train_scaled, columns=columns).set_index([train_df.index.values])\n",
    "    test_scaled_df = pd.DataFrame(test_scaled, columns=columns).set_index([test_df.index.values])\n",
    "\n",
    "#     #add the columns that are not scaled\n",
    "#     train_scaled_df = pd.concat([train_scaled_df, train_df.drop(columns = columns) ], axis= 1 )\n",
    "#     test_scaled_df = pd.concat([test_scaled_df, test_df.drop(columns = columns) ], axis= 1 )\n",
    "    #plot\n",
    "    for col in columns: \n",
    "        plt.figure(figsize=(13, 6))\n",
    "        plt.subplot(121)\n",
    "        plt.hist(train_df[col], ec='black')\n",
    "        plt.title('Original')\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel(\"counts\")\n",
    "        plt.subplot(122)\n",
    "        plt.hist(train_scaled_df[col],  ec='black')\n",
    "        plt.title('Scaled')\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel(\"counts\")\n",
    "\n",
    "\n",
    "\n",
    "    return train_scaled_df,  test_scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns =  X_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#test the function\n",
    "#train_Xscaled_df,  test_Xscaled_df= scaled_df( X_train , X_test, columns , MinMaxScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(df, target):\n",
    "    '''\n",
    "    This function brings in the dataframe and the target feature\n",
    "    then returns X_train, y_train, X_test and y_test with their respective shapes\n",
    "    '''\n",
    "    train = df[:'05-2012'] # includes everything until june 2016\n",
    "    test = df['06-2012':\"2012\"] #includes last 6 months\n",
    "\n",
    "    # split train into X (dataframe, drop target) & y (series, keep target only)\n",
    "    X_train = train.drop(columns=[target])\n",
    "    y_train = train[target]\n",
    "\n",
    "    # split test into X (dataframe, drop target) & y (series, keep target only)\n",
    "    X_test = test.drop(columns=[target])\n",
    "    y_test = test[target]\n",
    "\n",
    "    # Have function print datasets shape\n",
    "    print(f'X_train -> {X_train.shape}')\n",
    "    print(f'X_test -> {X_test.shape}')\n",
    "\n",
    "    return train, X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_scale and scale (df, target, scaler):\n",
    "    '''\n",
    "    takes in a df and creates dummy variables, select only the numeric columns and  split into X_train, y_train, \n",
    "    X_test, y_test and scaled X_train, X_test.\n",
    "    return   X_train_scaled, y_train_scaled, X_test, y_test\n",
    "    '''\n",
    "\n",
    "\n",
    "\n",
    "    #split\n",
    "    train, X_train, y_train, X_test, y_test = train_test(num_df, target)\n",
    "\n",
    "    #select the columns to scale\n",
    "    columns =  X_train.select_dtypes(exclude='object').columns.to_list()\n",
    "    #scale \n",
    "    X_train_scaled, X_test_scaled = scaled_df( X_train , X_test, columns , scaler)\n",
    "\n",
    "    return train, X_train_scaled, X_test_scaled, y_train, y_test\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split\n",
    "train, test, X_train, y_train, X_test, y_test = new_wrangle.train_test(df, 'weekly_sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the columns to scale\n",
    "col =  X_train.select_dtypes(exclude='object').columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale \n",
    "X_train_scaled, X_test_scaled = scaled_df( X_train , X_test, col , MinMaxScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train, X_train_scaled, y_train_scaled, X_test, y_test = prepare_modeling_dummies (df, 'weekly_sales', MinMaxScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train, test,  X_train_scaled, X_test_scaled, y_train, y_test = new_wrangle.split_scale(df, 'weekly_sales', MinMaxScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid blue\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle and split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's test the functions wrangle and split and scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =new_wrangle.wrangle_walmart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6435 entries, 2010-02-05_store_1_2010-02-12 to 2012-10-26_store_45_nan\n",
      "Data columns (total 34 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   store_id                 6435 non-null   object        \n",
      " 1   this_week_date           6435 non-null   datetime64[ns]\n",
      " 2   this_week_sales          6435 non-null   float64       \n",
      " 3   this_week_holiday_flag   6435 non-null   int64         \n",
      " 4   temperature              6435 non-null   int64         \n",
      " 5   fuel_price               6435 non-null   float64       \n",
      " 6   CPI                      6435 non-null   float64       \n",
      " 7   this_week_unemployment   6435 non-null   float64       \n",
      " 8   store_type               6435 non-null   object        \n",
      " 9   store_size               6435 non-null   int64         \n",
      " 10  next_week_1_year_ago     4140 non-null   float64       \n",
      " 11  next_week_sales_target   6390 non-null   float64       \n",
      " 12  next_week_date           6390 non-null   datetime64[ns]\n",
      " 13  next_week_holiday_flag   6390 non-null   float64       \n",
      " 14  next_week_season         4095 non-null   object        \n",
      " 15  this_week_season         4095 non-null   object        \n",
      " 16  next_week_holiday_name   6435 non-null   object        \n",
      " 17  christmas                6435 non-null   uint8         \n",
      " 18  labor_day                6435 non-null   uint8         \n",
      " 19  pre_christmas            6435 non-null   uint8         \n",
      " 20  super_bowl               6435 non-null   uint8         \n",
      " 21  thanksgiving             6435 non-null   uint8         \n",
      " 22  fuel_4wk_rolling         6432 non-null   float64       \n",
      " 23  cpi_4wk_rolling          6432 non-null   float64       \n",
      " 24  unemp_4wk_rolling        6432 non-null   float64       \n",
      " 25  avgMoM_perc_fuel         6428 non-null   float64       \n",
      " 26  avgMoM_perc_cpi          6428 non-null   float64       \n",
      " 27  avgMoM_perc_unemp        6428 non-null   float64       \n",
      " 28  fuel_quarterly_rolling   6424 non-null   float64       \n",
      " 29  cpi_quarterly_rolling    6424 non-null   float64       \n",
      " 30  unemp_quarterly_rolling  6424 non-null   float64       \n",
      " 31  avgQoQ_perc_fuel         6412 non-null   float64       \n",
      " 32  avgQoQ_perc_cpi          6412 non-null   float64       \n",
      " 33  avgQoQ_perc_unemp        6412 non-null   float64       \n",
      "dtypes: datetime64[ns](2), float64(19), int64(3), object(5), uint8(5)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**  we have nulls in our df because we created a new column next_week_1_year_ago  that's why the fisrt year has nulls because we dond have information about the previous year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6435, 34)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no_holiday       5805\n",
       "pre_christmas     180\n",
       "super_bowl        135\n",
       "labor_day         135\n",
       "thanksgiving       90\n",
       "christmas          90\n",
       "Name: next_week_holiday_name, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.next_week_holiday_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -> (2866, 32)\n",
      "test -> (1229, 32)\n"
     ]
    }
   ],
   "source": [
    "train, test,  X_train_scaled, X_test_scaled, y_train, y_test = new_wrangle.split_scale(df, 'next_week_sales_target', MinMaxScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2866 entries, 2011-09-16_store_12_2011-09-23 to 2011-09-16_store_40_2011-09-23\n",
      "Data columns (total 32 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   store_id                 2866 non-null   object \n",
      " 1   this_week_sales          2866 non-null   float64\n",
      " 2   this_week_holiday_flag   2866 non-null   int64  \n",
      " 3   temperature              2866 non-null   int64  \n",
      " 4   fuel_price               2866 non-null   float64\n",
      " 5   CPI                      2866 non-null   float64\n",
      " 6   this_week_unemployment   2866 non-null   float64\n",
      " 7   store_type               2866 non-null   object \n",
      " 8   store_size               2866 non-null   int64  \n",
      " 9   next_week_1_year_ago     2866 non-null   float64\n",
      " 10  next_week_sales_target   2866 non-null   float64\n",
      " 11  next_week_holiday_flag   2866 non-null   float64\n",
      " 12  next_week_season         2866 non-null   object \n",
      " 13  this_week_season         2866 non-null   object \n",
      " 14  next_week_holiday_name   2866 non-null   object \n",
      " 15  christmas                2866 non-null   uint8  \n",
      " 16  labor_day                2866 non-null   uint8  \n",
      " 17  pre_christmas            2866 non-null   uint8  \n",
      " 18  super_bowl               2866 non-null   uint8  \n",
      " 19  thanksgiving             2866 non-null   uint8  \n",
      " 20  fuel_4wk_rolling         2866 non-null   float64\n",
      " 21  cpi_4wk_rolling          2866 non-null   float64\n",
      " 22  unemp_4wk_rolling        2866 non-null   float64\n",
      " 23  avgMoM_perc_fuel         2866 non-null   float64\n",
      " 24  avgMoM_perc_cpi          2866 non-null   float64\n",
      " 25  avgMoM_perc_unemp        2866 non-null   float64\n",
      " 26  fuel_quarterly_rolling   2866 non-null   float64\n",
      " 27  cpi_quarterly_rolling    2866 non-null   float64\n",
      " 28  unemp_quarterly_rolling  2866 non-null   float64\n",
      " 29  avgQoQ_perc_fuel         2866 non-null   float64\n",
      " 30  avgQoQ_perc_cpi          2866 non-null   float64\n",
      " 31  avgQoQ_perc_unemp        2866 non-null   float64\n",
      "dtypes: float64(19), int64(3), object(5), uint8(5)\n",
      "memory usage: 640.9+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2866 entries, 2011-09-16_store_12_2011-09-23 to 2011-09-16_store_40_2011-09-23\n",
      "Data columns (total 26 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   this_week_sales          2866 non-null   float64\n",
      " 1   this_week_holiday_flag   2866 non-null   float64\n",
      " 2   temperature              2866 non-null   float64\n",
      " 3   fuel_price               2866 non-null   float64\n",
      " 4   CPI                      2866 non-null   float64\n",
      " 5   this_week_unemployment   2866 non-null   float64\n",
      " 6   store_size               2866 non-null   float64\n",
      " 7   next_week_1_year_ago     2866 non-null   float64\n",
      " 8   next_week_holiday_flag   2866 non-null   float64\n",
      " 9   christmas                2866 non-null   float64\n",
      " 10  labor_day                2866 non-null   float64\n",
      " 11  pre_christmas            2866 non-null   float64\n",
      " 12  super_bowl               2866 non-null   float64\n",
      " 13  thanksgiving             2866 non-null   float64\n",
      " 14  fuel_4wk_rolling         2866 non-null   float64\n",
      " 15  cpi_4wk_rolling          2866 non-null   float64\n",
      " 16  unemp_4wk_rolling        2866 non-null   float64\n",
      " 17  avgMoM_perc_fuel         2866 non-null   float64\n",
      " 18  avgMoM_perc_cpi          2866 non-null   float64\n",
      " 19  avgMoM_perc_unemp        2866 non-null   float64\n",
      " 20  fuel_quarterly_rolling   2866 non-null   float64\n",
      " 21  cpi_quarterly_rolling    2866 non-null   float64\n",
      " 22  unemp_quarterly_rolling  2866 non-null   float64\n",
      " 23  avgQoQ_perc_fuel         2866 non-null   float64\n",
      " 24  avgQoQ_perc_cpi          2866 non-null   float64\n",
      " 25  avgQoQ_perc_unemp        2866 non-null   float64\n",
      "dtypes: float64(26)\n",
      "memory usage: 604.5+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#explore our target\n",
    "plt.figure(figsize=(8, 10))\n",
    "sns.histplot(train,\n",
    "                 x=train['next_week_sales_target'],\n",
    "                 #hue='loan_status',\n",
    "                 multiple='layer'\n",
    "                 )\n",
    "plt.title(\"Distribution of Next week sales\")\n",
    "plt.xlabel('Weekly sales in dollars')\n",
    "plt.ylabel('Number of weeks')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ticklabel_format(style = 'plain')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(train['next_week_sales_target'])\n",
    "plt.xticks(rotation=45)\n",
    "#plt.ticklabel_format(style = 'plain')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(train['next_week_sales_target'])\n",
    "plt.xlim(2500000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "sns.heatmap(train.corr(), cmap='coolwarm', annot=True, linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the relation of my target with all the featues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#let's focus on my target\n",
    "plt.figure(figsize=(8, 12))\n",
    "heatmap = sns.heatmap(train.corr()[['next_week_sales_target']].sort_values(by='next_week_sales_target', ascending=False), vmin=-3, vmax=3, annot=True, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**takeaways**\n",
    "- next_week_1_year_ago, this_week_sales and store_size have stroger correlation with out target\n",
    "- pre_christmas has also a positive correlation\n",
    "- \n",
    "- negative correlation this_week_unemployment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration target vs Fearture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -  weekly_sales vs store_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "sns.jointplot(x= 'weekly_sales', y= 'store_size', data = train, hue ='season')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "**takeaways**\n",
    "- the small the store, less weekly sales\n",
    "- winter has the greater weekly sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -  weekly_sales vs temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "sns.jointplot(x= 'weekly_sales', y= 'temperature', data = train, hue= \"season\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways**\n",
    "- Winter and fall have the greater weekly_sales. may it is because of christmas and blackfriday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# winter_df = train[train.season == \"Winter\"][['weekly_sales', 'temperature', 'season']]\n",
    "# winter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sns.jointplot(x= 'weekly_sales', y= 'temperature', data = winter_df, hue= \"season\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.season.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_list = ['blue','green', 'red', 'orange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for season, color in zip(train.season.unique(), color_list):\n",
    "    print(season, color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for season, c in zip(train.season.unique(), color_list):\n",
    "    print(season)\n",
    "    sns.jointplot(x= 'weekly_sales', y= 'temperature', data = train[train.season==season], color= c)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -  weekly_sales vs holiday_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "sns.boxplot(x= train['holiday_name'], y =train['weekly_sales'] )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways**\n",
    "- the 2 holidays with the greatest weekle_sales are pre_christmas and thanksgiving\n",
    "-we can see christmas does not have large amount of weekly_sales it is because the people buy before christmas , it is not like blackfriday that the people actually buy in this specific week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - weekly_sales vs season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "sns.boxplot(x= train['season'], y =train['weekly_sales'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**takeaways**\n",
    "- we see some outliers but basically there are the weekly sales for thanksgiving and christmas (pre)\n",
    "- we can say summer has the lowest range of weekly sales amout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for season, c in zip(train.season.unique(), color_list):\n",
    "    print(season)\n",
    "    sns.boxplot(x= train[train.season== season]['weekly_sales'], color = c )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**takeaways**\n",
    "- it looks like summer has the lowest median "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.head(1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor \n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# #conver y_train y _ validate to df\n",
    "y_train_df = pd.DataFrame( {'actual': y_train})\n",
    "y_test_df = pd.DataFrame( {'actual': y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_kbest  (X_df, y_df, n_features):\n",
    "    '''\n",
    "    Takes in the predictors, the target, and the number of features to select (k) ,\n",
    "    and returns the names of the top k selected features based on the SelectKBest class\n",
    "    \n",
    "    X_df : the predictors\n",
    "    y_df : the target\n",
    "    n_features : the number of features to select (k)\n",
    "    Example\n",
    "    select_kbest(X_train_scaled, y_train, 2)\n",
    "    '''\n",
    "    \n",
    "    f_selector = SelectKBest(score_func=f_regression, k= n_features)\n",
    "    f_selector.fit(X_df, y_df)\n",
    "    mask = f_selector.get_support()\n",
    "    X_df.columns[mask]\n",
    "    top = list(X_df.columns[mask])\n",
    "    print(f'The top {n_features} selected feautures based on the SelectKBest class are: {top}' )\n",
    "    return top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_rfe (X_df, y_df, n_features, method):\n",
    "    '''\n",
    "    Takes in the predictors, the target, and the number of features to select (k) ,\n",
    "    and returns the names of the top k selected features based on the Recursive Feature Elimination (RFE)\n",
    "    \n",
    "    X_df : the predictors\n",
    "    y_df : the target\n",
    "    n_features : the number of features to select (k)\n",
    "    method : LinearRegression, LassoLars, TweedieRegressor\n",
    "    Example\n",
    "    select_rfe(X_train_scaled, y_train, 2, LinearRegression())\n",
    "    '''\n",
    "    lm = method\n",
    "    rfe = RFE(estimator=lm, n_features_to_select= n_features)\n",
    "    rfe.fit(X_df, y_df)\n",
    "    top_rfe = list(X_df.columns[rfe.support_])\n",
    "    print(f'The top {n_features} selected feautures based on the the RFE class class are: {top_rfe}' )\n",
    "    print(pd.Series(dict(zip(X_df.columns, rfe.ranking_))).sort_values())\n",
    "    return top_rfe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_errors(df, y, yhat):\n",
    "    '''\n",
    "    Takes in a dataframe , y = column with actual_values and yhat= name of the columns with predicted_values\n",
    "    and calculate:\n",
    "    sum of squared errors (SSE)\n",
    "    explained sum of squares (ESS)\n",
    "    total sum of squares (TSS)\n",
    "    mean squared error (MSE)\n",
    "    root mean squared error (RMSE)\n",
    "    Returns a dictionary with all these values.\n",
    "    Example:\n",
    "    plot_residuals(df, 'tip', 'yhat')\n",
    "    '''\n",
    "    #import\n",
    "    from sklearn.metrics import  mean_squared_error\n",
    "    from math import sqrt\n",
    "    \n",
    "    \n",
    "    #calculate SSE using sklearn\n",
    "    SSE = mean_squared_error(df[y], df[yhat])*len(df)\n",
    "    #explained sum of squares (ESS)\n",
    "    ESS = ((df[yhat] - df[y].mean())**2).sum()\n",
    "    #total sum of squares (TSS)\n",
    "    TSS = ((df[y] - df[y].mean())**2).sum()\n",
    "    #mean squared error (MSE)\n",
    "    MSE = mean_squared_error(df[y], df[yhat])\n",
    "    #root mean squared error (RMSE)\n",
    "    RMSE = sqrt(MSE)\n",
    "    \n",
    "    #create a dictionary\n",
    "    m= {\n",
    "        'sse': SSE,\n",
    "        'ess': ESS,\n",
    "        'rmse': RMSE,\n",
    "        'tss': TSS,\n",
    "        'mse': MSE,\n",
    "        'r2': ESS/TSS,\n",
    "    }\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model (X_df_scaled, y_df, actual, method, name):\n",
    "    '''\n",
    "    takes in features scaled df, target df, name of actual target, \n",
    "    type of method and the name of the selected method and \n",
    "    returns a dictionary that contains calculated regression errors.\n",
    "    \n",
    "    X_df_scaled : df that contains scaled featues\n",
    "    y_df: target df\n",
    "    actual: name of the column where is actual value of the target\n",
    "    mehod: type of method to create the model object\n",
    "    name: enter the new name for your model\n",
    "    \n",
    "    Example:\n",
    "    create_model(X_train_scaled[top_sb], y_train, 'actual', LinearRegression(normalize=True), 'modelOLS' )\n",
    "    '''\n",
    "    # fit the thing\n",
    "    method.fit(X_df_scaled, y_df[actual])\n",
    "\n",
    "    # predict train\n",
    "    y_df[name] = method.predict(X_df_scaled)\n",
    "\n",
    "    #calculate regression errors using a created function\n",
    "    train_eval = regression_errors(y_df, actual, name)\n",
    "\n",
    "    return train_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(metric_df):\n",
    "    \n",
    "    from IPython.display import display, HTML\n",
    "    rmse_base = metric_df.iloc[0,2]\n",
    "    print(f'These are the models that perform better than our baseline rmse: {rmse_base}')\n",
    "    dfs =metric_df[['model', 'rmse_validate']][metric_df['rmse_validate'] < rmse_base]\n",
    "    display(HTML(dfs.to_html()))\n",
    "    \n",
    "    \n",
    "    min_val = metric_df['rmse_validate'].idxmin()\n",
    "    metric_df.iloc[min_val][0]\n",
    "    rsme_bet = round(metric_df['rmse_validate'].iloc[min_val], 2)\n",
    "    print('-----------------------------------------------------------------------------------------------')\n",
    "    print(f'   ********** The model with the less  rmse_validate  is {metric_df.iloc[min_val][0] }  rmse:{rsme_bet} **********             ')\n",
    "    print('-----------------------------------------------------------------------------------------------')\n",
    "    print(' ')\n",
    "    min_val = metric_df['r^2_validate'].idxmax()\n",
    "    metric_df.iloc[min_val][0]\n",
    "    print(f'The model with r^2 validate closer to 1 is ', metric_df.iloc[min_val][0])\n",
    "    \n",
    "    display(HTML(metric_df.to_html()))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_errors(df, y, option ):\n",
    "    '''\n",
    "    Takes in a dataframe , y = column with actual_values \n",
    "    and calculate:\n",
    "    sum of squared errors (SSE)\n",
    "    explained sum of squares (ESS)\n",
    "    total sum of squares (TSS)\n",
    "    mean squared error (MSE)\n",
    "    root mean squared error (RMSE)\n",
    "    Returns a dictionary with all these values\n",
    "    Example:\n",
    "    baseline_mean_errors(y_train, 'actual')\n",
    "    '''\n",
    "    #import\n",
    "    from sklearn.metrics import  mean_squared_error\n",
    "    from math import sqrt\n",
    "\n",
    "    #baseline\n",
    "    if option == 'mean':\n",
    "        df['yhat_baseline_mean'] = df[y].mean()\n",
    "        col = 'yhat_baseline_mean'\n",
    "    elif option == 'median':\n",
    "        df['yhat_baseline_median'] = df[y].median()\n",
    "        col = 'yhat_baseline_median'\n",
    "    else:\n",
    "        return print(\"please select the correct option: 'mean' or 'median' \")\n",
    "        \n",
    "    \n",
    "\n",
    "    #calculate SSE using sklearn\n",
    "    SSE_baseline = mean_squared_error(df[y], df[col])*len(df)\n",
    "    #explained sum of squares (ESS)\n",
    "    ESS_b = ((df[col] - df[y].mean())**2).sum()\n",
    "    #total sum of squares (TSS)\n",
    "    TSS_b = ((df[y] - df[y].mean())**2).sum()\n",
    "    #mean squared error (MSE)\n",
    "    MSE_baseline = mean_squared_error(df[y], df[col])\n",
    "    #root mean squared error (RMSE)\n",
    "    RMSE_baseline = sqrt(MSE_baseline)\n",
    "    \n",
    "    #create dicc\n",
    "    b ={\n",
    "        'sse': SSE_baseline,\n",
    "        'mse': MSE_baseline,\n",
    "        'rmse': RMSE_baseline,\n",
    "         'tss': TSS_b,\n",
    "        'ess' : ESS_b,\n",
    "        'mse': MSE_baseline,\n",
    "        'r2': ESS_b/TSS_b,       \n",
    "    }\n",
    "\n",
    "    return b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Baseline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #create baseline using mean (I'm using my function to calculate rmse)\n",
    "# tra = baseline_errors(y_train_df, 'actual', 'mean')\n",
    "# tra['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #create a df to store metrics\n",
    "# metric_df = pd.DataFrame(data = [{\n",
    "#     'model': 'mean_baseline',\n",
    "#     'rmse_train' : round(tra['rmse'], 2),\n",
    "#     'r^2' : 0}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#baseline version 2 using last years sales\n",
    "y_train_df['last_year_baseline'] = train['next_week_1_year_ago']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.metrics import mean_squared_error, explained_variance_score\n",
    "#calculate RMSE for baseline model\n",
    "rmse_baseline2_train= math.sqrt(mean_squared_error(y_train_df.actual, y_train_df.last_year_baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91145.28223498359"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_baseline2_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the mretic to our df\n",
    "metric_df = pd.DataFrame(data = [{\n",
    "    'model': 'baseline(using last year sales)',\n",
    "    'rmse_train':rmse_baseline2_train,    \n",
    "    'r^2' : 0}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>rmse_train</th>\n",
       "      <th>r^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline(using last year sales)</td>\n",
       "      <td>91145.282235</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             model    rmse_train  r^2\n",
       "0  baseline(using last year sales)  91145.282235    0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - select k best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98419954, 0.98313829, 0.98420746])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the model\n",
    "clf = LinearRegression(normalize=True)\n",
    "#cv = number of folds\n",
    "cross_val_score(clf, X_train_scaled, y_train, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['explained_variance', 'r2', 'max_error', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_root_mean_squared_error', 'neg_mean_poisson_deviance', 'neg_mean_gamma_deviance', 'accuracy', 'roc_auc', 'roc_auc_ovr', 'roc_auc_ovo', 'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'neg_brier_score', 'adjusted_rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.metrics.SCORERS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98599044, 0.98226797, 0.98253562, 0.98596136, 0.98314991])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the model\n",
    "clf = LinearRegression(normalize=True)\n",
    "#cv = number of folds\n",
    "cross_val_score(clf, X_train_scaled, y_train, cv=5, scoring = 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-69529.70428164, -71656.45914894, -71583.06247297])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the model\n",
    "clf = LinearRegression(normalize=True)\n",
    "#cv = number of folds\n",
    "cross_val_score(clf, X_train_scaled, y_train, cv=3, scoring = 'neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98419954, 0.98313829, 0.98420746])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the model\n",
    "clf = LinearRegression(normalize=False)\n",
    "#cv = number of folds\n",
    "cross_val_score(clf, X_train_scaled, y_train, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearRegression(),\n",
       "             param_grid={'fit_intercept': [True, False],\n",
       "                         'normalize': [True, False]},\n",
       "             scoring='neg_root_mean_squared_error')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#specify the parameters we wish to use as a dictionary, then use that dictionary when we create the class.\n",
    "params = {'normalize': [ True, False],\n",
    "          'fit_intercept': [True, False]}\n",
    "\n",
    "ols = LinearRegression()\n",
    "\n",
    "grid = GridSearchCV(ols, params, cv=5, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_fit_intercept', 'param_normalize', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see the cross validation results in the cv_results_ property of the object we created.\n",
    "results = grid.cv_results_\n",
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-70476.1904101 , -70476.1904101 , -72272.95355196, -72272.95355196])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I will use mean_test_score\n",
    "test_scores = results['mean_test_score']\n",
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'fit_intercept': True, 'normalize': True},\n",
       " {'fit_intercept': True, 'normalize': False},\n",
       " {'fit_intercept': False, 'normalize': True},\n",
       " {'fit_intercept': False, 'normalize': False}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = results['params']\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_intercept</th>\n",
       "      <th>normalize</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-72272.953552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-72272.953552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-70476.190410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-70476.190410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_intercept  normalize         score\n",
       "2          False       True -72272.953552\n",
       "3          False      False -72272.953552\n",
       "1           True      False -70476.190410\n",
       "0           True       True -70476.190410"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can combine these features together into a data frame to see how our different models perform:\n",
    "for p, s in zip(params, test_scores):\n",
    "    p['score'] = s\n",
    "\n",
    "pd.DataFrame(params).sort_values(by='score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearch ( X_df , y_df , model, params, score):\n",
    "    '''\n",
    "    '''\n",
    "    grid = GridSearchCV(model, params, cv=5, scoring= score )\n",
    "    grid.fit(X_df, y_df)\n",
    "    #see the cross validation results in the cv_results_ property of the object we created.\n",
    "    results = grid.cv_results_\n",
    "    # I will use mean_test_score\n",
    "    test_scores = results['mean_test_score']\n",
    "    #GETTING THE PARAMETERS\n",
    "    params = results['params']\n",
    "    #We can combine these features together into a data frame to see how our different models perform:\n",
    "    for p, s in zip(params, test_scores):\n",
    "        p['score'] = s\n",
    "\n",
    "    return pd.DataFrame(params).sort_values(by='score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  LinearRegression (OLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify the parameters we wish to use as a dictionary, then use that dictionary when we create the class.\n",
    "params = {'normalize': [ True, False],\n",
    "          'fit_intercept': [True, False]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_intercept</th>\n",
       "      <th>normalize</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-72272.953552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-72272.953552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-70476.190410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-70476.190410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_intercept  normalize         score\n",
       "2          False       True -72272.953552\n",
       "3          False      False -72272.953552\n",
       "1           True      False -70476.190410\n",
       "0           True       True -70476.190410"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use a gridsearch function using \n",
    "gridsearch (X_train_scaled, y_train, LinearRegression() , params, 'neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS uising  select K best (6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 10 selected feautures based on the SelectKBest class are: ['this_week_sales', 'CPI', 'this_week_unemployment', 'store_size', 'next_week_1_year_ago', 'pre_christmas', 'cpi_4wk_rolling', 'unemp_4wk_rolling', 'cpi_quarterly_rolling', 'unemp_quarterly_rolling']\n"
     ]
    }
   ],
   "source": [
    "#using my function for SelectkBest\n",
    "top_sb =select_kbest(X_train_scaled, y_train, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73278.63464117885"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the model\n",
    "ols_sb = create_model(X_train_scaled[top_sb], y_train_df, 'actual',\\\n",
    "                       LinearRegression(normalize=True,\\\n",
    "                        fit_intercept=True ), 'modelOLS' )\n",
    "ols_sb['rmse']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-73828.51208786, -73408.20028783, -74244.87809008])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the model\n",
    "clf = LinearRegression(normalize=True, fit_intercept=True )\n",
    "#cv = number of folds\n",
    "cross_val_score(clf, X_train_scaled[top_sb], y_train, cv=3, scoring = 'neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS uising  RFE (8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 10 selected feautures based on the the RFE class class are: ['this_week_sales', 'CPI', 'this_week_unemployment', 'next_week_1_year_ago', 'christmas', 'thanksgiving', 'cpi_4wk_rolling', 'avgMoM_perc_unemp', 'cpi_quarterly_rolling', 'unemp_quarterly_rolling']\n",
      "this_week_sales             1\n",
      "unemp_quarterly_rolling     1\n",
      "cpi_quarterly_rolling       1\n",
      "avgMoM_perc_unemp           1\n",
      "CPI                         1\n",
      "this_week_unemployment      1\n",
      "cpi_4wk_rolling             1\n",
      "next_week_1_year_ago        1\n",
      "thanksgiving                1\n",
      "christmas                   1\n",
      "avgQoQ_perc_unemp           2\n",
      "store_size                  3\n",
      "fuel_quarterly_rolling      4\n",
      "avgMoM_perc_fuel            5\n",
      "fuel_4wk_rolling            6\n",
      "avgQoQ_perc_fuel            7\n",
      "this_week_holiday_flag      8\n",
      "fuel_price                  9\n",
      "unemp_4wk_rolling          10\n",
      "avgMoM_perc_cpi            11\n",
      "labor_day                  12\n",
      "super_bowl                 13\n",
      "temperature                14\n",
      "avgQoQ_perc_cpi            15\n",
      "pre_christmas              16\n",
      "next_week_holiday_flag     17\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#uise the fucntion to get RFE\n",
    "top_rfe = select_rfe(X_train_scaled, y_train, 10,LinearRegression(normalize=True, fit_intercept=True ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71859.75745004068"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the model\n",
    "ols_rfe = create_model(X_train_scaled[top_rfe], y_train_df, 'actual', LinearRegression(normalize=True, fit_intercept=True ), 'modelOLS' )\n",
    "ols_rfe['rmse']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-72127.07288044, -73241.00581704, -72267.9117694 ])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the model\n",
    "clf = LinearRegression(normalize=True, fit_intercept=True )\n",
    "#cv = number of folds\n",
    "cross_val_score(clf, X_train_scaled[top_rfe], y_train, cv=3, scoring = 'neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: we are going to use ols_rfe  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the mretic to our df\n",
    "metric_df = metric_df.append(\n",
    "    {\n",
    "    'model': 'ols_rfe',\n",
    "    'rmse_train': ols_rfe['rmse'],    \n",
    "    'r^2' : ols_rfe['r2']}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>rmse_train</th>\n",
       "      <th>r^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline(using last year sales)</td>\n",
       "      <td>91145.282235</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ols_rfe</td>\n",
       "      <td>71859.757450</td>\n",
       "      <td>0.983443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             model    rmse_train       r^2\n",
       "0  baseline(using last year sales)  91145.282235  0.000000\n",
       "1                          ols_rfe  71859.757450  0.983443"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LassoLars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify the parameters we wish to use as a dictionary, then use that dictionary when we create the class.\n",
    "params = {\n",
    "          'normalize': [True, False],\n",
    "          'fit_intercept':[True, False],\n",
    "           'alpha': [1.0, 0]\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>fit_intercept</th>\n",
       "      <th>normalize</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-72298.372878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-72298.372878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-72272.953552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-72272.953552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-70476.190410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-70476.190410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-70458.146015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-70440.674321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alpha  fit_intercept  normalize         score\n",
       "2    1.0          False       True -72298.372878\n",
       "3    1.0          False      False -72298.372878\n",
       "6    0.0          False       True -72272.953552\n",
       "7    0.0          False      False -72272.953552\n",
       "5    0.0           True      False -70476.190410\n",
       "4    0.0           True       True -70476.190410\n",
       "0    1.0           True       True -70458.146015\n",
       "1    1.0           True      False -70440.674321"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use the function to get the combinations of parameters\n",
    "gridsearch (X_train_scaled, y_train, LassoLars() , params, 'neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 6 selected feautures based on the the RFE class class are: ['this_week_sales', 'this_week_unemployment', 'next_week_1_year_ago', 'christmas', 'thanksgiving', 'unemp_quarterly_rolling']\n",
      "this_week_sales             1\n",
      "unemp_quarterly_rolling     1\n",
      "thanksgiving                1\n",
      "christmas                   1\n",
      "this_week_unemployment      1\n",
      "next_week_1_year_ago        1\n",
      "avgMoM_perc_unemp           2\n",
      "avgQoQ_perc_unemp           3\n",
      "store_size                  4\n",
      "avgMoM_perc_fuel            5\n",
      "fuel_quarterly_rolling      6\n",
      "fuel_4wk_rolling            7\n",
      "avgQoQ_perc_fuel            8\n",
      "this_week_holiday_flag      9\n",
      "avgMoM_perc_cpi            10\n",
      "fuel_price                 11\n",
      "next_week_holiday_flag     12\n",
      "temperature                13\n",
      "CPI                        14\n",
      "avgQoQ_perc_cpi            15\n",
      "pre_christmas              16\n",
      "super_bowl                 17\n",
      "cpi_4wk_rolling            18\n",
      "unemp_4wk_rolling          19\n",
      "labor_day                  20\n",
      "cpi_quarterly_rolling      21\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#get the 9 features\n",
    "top_rfe = select_rfe(X_train_scaled, y_train, 6, LassoLars(alpha = 1, normalize= False, fit_intercept= True) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72080.26921283794"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the model\n",
    "lasso_rfe = create_model(X_train_scaled[top_rfe], y_train_df, 'actual', LassoLars(alpha = 1, normalize= False, fit_intercept= True), 'modelLasso' )\n",
    "lasso_rfe['rmse']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-72369.74422049, -73054.01907945, -72590.01601532])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the model\n",
    "clf = LassoLars(alpha = 1, normalize= False, fit_intercept= True)\n",
    "#cv = number of folds\n",
    "cross = cross_val_score(clf, X_train_scaled[top_rfe], y_train, cv=3, scoring = 'neg_root_mean_squared_error')\n",
    "cross"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select K best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 10 selected feautures based on the SelectKBest class are: ['this_week_sales', 'CPI', 'this_week_unemployment', 'store_size', 'next_week_1_year_ago', 'pre_christmas', 'cpi_4wk_rolling', 'unemp_4wk_rolling', 'cpi_quarterly_rolling', 'unemp_quarterly_rolling']\n"
     ]
    }
   ],
   "source": [
    "#using my function for SelectkBest\n",
    "top_sb =select_kbest(X_train_scaled, y_train, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73281.87552494287"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_skb = create_model(X_train_scaled[top_sb], y_train_df, 'actual', LassoLars(alpha = 1, normalize= False, fit_intercept= True), 'modelLasso' )\n",
    "lasso_skb['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-73875.3247233 , -73345.36555372, -74270.0989156 ])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the model\n",
    "clf = LassoLars(alpha = 1, normalize= False, fit_intercept= True)\n",
    "#cv = number of folds\n",
    "cross= cross_val_score(clf, X_train_scaled[top_sb], y_train, cv=3, scoring = 'neg_root_mean_squared_error')\n",
    "cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the best model and its metrics\n",
    "metric_df = metric_df.append(\n",
    "    {\n",
    "    'model': 'lasso_rfe',\n",
    "    'rmse_train': lasso_rfe['rmse'],    \n",
    "    'r^2' : lasso_rfe['r2']}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>rmse_train</th>\n",
       "      <th>r^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline(using last year sales)</td>\n",
       "      <td>91145.282235</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ols_rfe</td>\n",
       "      <td>71859.757450</td>\n",
       "      <td>0.983443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lasso_rfe</td>\n",
       "      <td>72080.269213</td>\n",
       "      <td>0.983309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             model    rmse_train       r^2\n",
       "0  baseline(using last year sales)  91145.282235  0.000000\n",
       "1                          ols_rfe  71859.757450  0.983443\n",
       "2                        lasso_rfe  72080.269213  0.983309"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## TweedieRegressor (GLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - GridSearch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify the parameters we wish to use as a dictionary, then use that dictionary when we create the class.\n",
    "params = {\n",
    "          'power': [0.0, 1],\n",
    "           'fit_intercept' : [True , False],\n",
    "          'warm_start': [True, False], \n",
    "           'alpha': [1.0, 0.0]\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>fit_intercept</th>\n",
       "      <th>power</th>\n",
       "      <th>warm_start</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.109649e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.109649e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.106117e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.106117e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-5.226843e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-5.226843e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-4.957444e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-4.957444e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.442832e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.442832e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.442744e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.442744e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-7.442288e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-7.442288e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-7.045040e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-7.045040e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    alpha  fit_intercept  power  warm_start         score\n",
       "6     1.0          False    1.0        True -1.109649e+06\n",
       "7     1.0          False    1.0       False -1.109649e+06\n",
       "14    0.0          False    1.0        True -1.106117e+06\n",
       "15    0.0          False    1.0       False -1.106117e+06\n",
       "4     1.0          False    0.0        True -5.226843e+05\n",
       "5     1.0          False    0.0       False -5.226843e+05\n",
       "0     1.0           True    0.0        True -4.957444e+05\n",
       "1     1.0           True    0.0       False -4.957444e+05\n",
       "2     1.0           True    1.0        True -1.442832e+05\n",
       "3     1.0           True    1.0       False -1.442832e+05\n",
       "10    0.0           True    1.0        True -1.442744e+05\n",
       "11    0.0           True    1.0       False -1.442744e+05\n",
       "12    0.0          False    0.0        True -7.442288e+04\n",
       "13    0.0          False    0.0       False -7.442288e+04\n",
       "8     0.0           True    0.0        True -7.045040e+04\n",
       "9     0.0           True    0.0       False -7.045040e+04"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch (X_train_scaled, y_train,TweedieRegressor() , params, 'neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create model using RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 6 selected feautures based on the the RFE class class are: ['this_week_sales', 'store_size', 'next_week_1_year_ago', 'christmas', 'thanksgiving', 'avgQoQ_perc_unemp']\n",
      "this_week_sales             1\n",
      "thanksgiving                1\n",
      "christmas                   1\n",
      "next_week_1_year_ago        1\n",
      "store_size                  1\n",
      "avgQoQ_perc_unemp           1\n",
      "avgMoM_perc_fuel            2\n",
      "fuel_quarterly_rolling      3\n",
      "fuel_4wk_rolling            4\n",
      "avgQoQ_perc_fuel            5\n",
      "unemp_4wk_rolling           6\n",
      "this_week_unemployment      7\n",
      "this_week_holiday_flag      8\n",
      "avgMoM_perc_cpi             9\n",
      "unemp_quarterly_rolling    10\n",
      "avgMoM_perc_unemp          11\n",
      "labor_day                  12\n",
      "super_bowl                 13\n",
      "temperature                14\n",
      "fuel_price                 15\n",
      "avgQoQ_perc_cpi            16\n",
      "cpi_quarterly_rolling      17\n",
      "next_week_holiday_flag     18\n",
      "CPI                        19\n",
      "pre_christmas              20\n",
      "cpi_4wk_rolling            21\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#use function to get the top 6 RFE\n",
    "top_rfe = select_rfe(X_train_scaled, y_train, 6, TweedieRegressor(alpha =0 , fit_intercept= True, power=0 ,\\\n",
    "                                                                  warm_start= False) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71522.6640373484"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the model\n",
    "gml_rfe = create_model(X_train_scaled[top_rfe], y_train_df, 'actual',TweedieRegressor(alpha =0 , fit_intercept= True, power=0 ,\\\n",
    "                                                                  warm_start= False), 'modelgml' )\n",
    "gml_rfe['rmse']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-71446.65517559, -72245.35839113, -72581.66333012])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the model\n",
    "clf = TweedieRegressor(alpha =0 , fit_intercept= True, power=0 ,warm_start= False)\n",
    "#cv = number of folds\n",
    "cross = cross_val_score(clf, X_train_scaled[top_rfe], y_train, scoring = 'neg_root_mean_squared_error', cv=3)\n",
    "cross"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create model using select kbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 6 selected feautures based on the SelectKBest class are: ['this_week_sales', 'this_week_unemployment', 'store_size', 'next_week_1_year_ago', 'unemp_4wk_rolling', 'unemp_quarterly_rolling']\n"
     ]
    }
   ],
   "source": [
    "#using my function for SelectkBest\n",
    "top_sb =select_kbest(X_train_scaled, y_train, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73447.13066759182"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gml_skb = create_model(X_train_scaled[top_sb], y_train_df, 'actual',TweedieRegressor(alpha =0 , fit_intercept= True, power=0 ,\\\n",
    "                                                                  warm_start= False), 'modelgml' )\n",
    "gml_skb['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-74054.54562594, -73200.00828644, -74368.20223621])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the model\n",
    "clf = TweedieRegressor(alpha =0 , fit_intercept= True, power=0 ,warm_start= False)\n",
    "#cv = number of folds\n",
    "cross = cross_val_score(clf, X_train_scaled[top_sb], y_train, scoring = 'neg_root_mean_squared_error',cv=3)\n",
    "cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the best model\n",
    "metric_df = metric_df.append(\n",
    "    {\n",
    "    'model': 'gml_rfe',\n",
    "    'rmse_train': gml_rfe['rmse'],    \n",
    "    'r^2' : gml_rfe['r2']}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>rmse_train</th>\n",
       "      <th>r^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline(using last year sales)</td>\n",
       "      <td>91145.282235</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ols_rfe</td>\n",
       "      <td>71859.757450</td>\n",
       "      <td>0.983443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lasso_rfe</td>\n",
       "      <td>72080.269213</td>\n",
       "      <td>0.983309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gml_rfe</td>\n",
       "      <td>71522.664037</td>\n",
       "      <td>0.983598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             model    rmse_train       r^2\n",
       "0  baseline(using last year sales)  91145.282235  0.000000\n",
       "1                          ols_rfe  71859.757450  0.983443\n",
       "2                        lasso_rfe  72080.269213  0.983309\n",
       "3                          gml_rfe  71522.664037  0.983598"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  select k best "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 6 selected feautures based on the SelectKBest class are: ['this_week_sales', 'this_week_unemployment', 'store_size', 'next_week_1_year_ago', 'unemp_4wk_rolling', 'unemp_quarterly_rolling']\n"
     ]
    }
   ],
   "source": [
    "#using my function for SelectkBest\n",
    "top_sb =select_kbest(X_train_scaled, y_train, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the polynomial features to get a new set of features\n",
    "pf = PolynomialFeatures(degree = 3) \n",
    "\n",
    "# fit and transform X_train_scaled\n",
    "X_train_degree3 = pf.fit_transform(X_train_scaled[top_sb])\n",
    "\n",
    "# transform X_validate_scaled & X_test_scaled\n",
    "X_test_degree3 = pf.transform(X_test_scaled[top_sb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify the parameters we wish to use as a dictionary, then use that dictionary when we create the class.\n",
    "params = {\n",
    "          'normalize': [True, False],\n",
    "          'fit_intercept':[True, False],\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_intercept</th>\n",
       "      <th>normalize</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-68367.964689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-68367.964689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-68367.964689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-68367.964689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_intercept  normalize         score\n",
       "0           True       True -68367.964689\n",
       "1           True      False -68367.964689\n",
       "2          False       True -68367.964689\n",
       "3          False      False -68367.964689"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch (X_train_degree3, y_train, LinearRegression() , params, 'neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_intercept</th>\n",
       "      <th>normalize</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.984925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.984925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.984925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.984925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_intercept  normalize     score\n",
       "0           True       True  0.984925\n",
       "1           True      False  0.984925\n",
       "2          False       True  0.984925\n",
       "3          False      False  0.984925"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch (X_train_degree3, y_train, LinearRegression() , params, 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64044.02037218975"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pol_skb = create_model(X_train_degree3, y_train_df, 'actual',LinearRegression( normalize=False, fit_intercept = False ), 'modelpol' )\n",
    "pol_skb['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-66722.79374691, -70656.60660325, -72587.28808291])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the model\n",
    "clf = LinearRegression( normalize=False, fit_intercept = True )\n",
    "#cv = number of folds\n",
    "cross = cross_val_score(clf, X_train_degree3, y_train, cv=3, scoring = 'neg_root_mean_squared_error')\n",
    "cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df = metric_df.append(\n",
    "    {\n",
    "    'model': 'pol3_skb',\n",
    "    'rmse_train': pol_skb['rmse'],    \n",
    "    'r^2' : pol_skb['r2']}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 7 selected feautures based on the the RFE class class are: ['this_week_sales', 'CPI', 'next_week_1_year_ago', 'cpi_4wk_rolling', 'unemp_4wk_rolling', 'cpi_quarterly_rolling', 'unemp_quarterly_rolling']\n",
      "this_week_sales             1\n",
      "unemp_quarterly_rolling     1\n",
      "cpi_quarterly_rolling       1\n",
      "CPI                         1\n",
      "next_week_1_year_ago        1\n",
      "unemp_4wk_rolling           1\n",
      "cpi_4wk_rolling             1\n",
      "this_week_unemployment      2\n",
      "avgMoM_perc_unemp           3\n",
      "avgMoM_perc_cpi             4\n",
      "christmas                   5\n",
      "thanksgiving                6\n",
      "fuel_price                  7\n",
      "fuel_4wk_rolling            8\n",
      "store_size                  9\n",
      "avgQoQ_perc_unemp          10\n",
      "this_week_holiday_flag     11\n",
      "avgQoQ_perc_fuel           12\n",
      "avgQoQ_perc_cpi            13\n",
      "avgMoM_perc_fuel           14\n",
      "temperature                15\n",
      "super_bowl                 16\n",
      "pre_christmas              17\n",
      "fuel_quarterly_rolling     18\n",
      "labor_day                  19\n",
      "next_week_holiday_flag     20\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    " top_rfe = select_rfe(X_train_scaled, y_train, 7, LinearRegression(normalize=False, fit_intercept = False) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the polynomial features to get a new set of features\n",
    "pf = PolynomialFeatures(degree = 3) \n",
    "\n",
    "# fit and transform X_train_scaled\n",
    "X_train_degree3 = pf.fit_transform(X_train_scaled[top_rfe])\n",
    "\n",
    "# transform X_validate_scaled & X_test_scaled\n",
    "X_test_degree3 = pf.transform(X_test_scaled[top_rfe])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_intercept</th>\n",
       "      <th>normalize</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-65466.028958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-64896.793744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-64896.793744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-64896.793729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_intercept  normalize         score\n",
       "0           True       True -65466.028958\n",
       "2          False       True -64896.793744\n",
       "3          False      False -64896.793744\n",
       "1           True      False -64896.793729"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch (X_train_degree3, y_train, LinearRegression() , params, 'neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60488.51113347658"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the model\n",
    "pol_rfe = create_model(X_train_degree3, y_train_df, 'actual',LinearRegression( normalize=False, fit_intercept = True ), 'modelpol' )\n",
    "pol_rfe['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-65122.10841691, -67271.31287954, -66561.22897066])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the model\n",
    "clf = LinearRegression( normalize=True, fit_intercept = True )\n",
    "#cv = number of folds\n",
    "cross = cross_val_score(clf, X_train_degree3, y_train, cv=3, scoring = 'neg_root_mean_squared_error')\n",
    "cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df = metric_df.append(\n",
    "    {\n",
    "    'model': 'pol3_rfe',\n",
    "    'rmse_train': pol_rfe['rmse'],    \n",
    "    'r^2' : pol_rfe['r2']}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degree 2  with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the polynomial features to get a new set of features using the entire df\n",
    "pf = PolynomialFeatures(degree = 1) \n",
    "\n",
    "# fit and transform X_train_scaled\n",
    "X_train_degree2 = pf.fit_transform(X_train_scaled)\n",
    "\n",
    "# transform X_validate_scaled & X_test_scaled\n",
    "X_test_degree2 = pf.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_intercept</th>\n",
       "      <th>normalize</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-70476.19041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-70476.19041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-70476.19041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-70476.19041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_intercept  normalize        score\n",
       "2          False       True -70476.19041\n",
       "3          False      False -70476.19041\n",
       "1           True      False -70476.19041\n",
       "0           True       True -70476.19041"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch (X_train_degree2, y_train, LinearRegression() , params, 'neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69757.43755006164"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pol_dg2 = create_model(X_train_degree2, y_train_df, 'actual',LinearRegression( normalize=True, fit_intercept = True ), 'modelpol' )\n",
    "pol_dg2['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-69529.70428164, -71656.45914894, -71583.06247297])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the model\n",
    "clf = LinearRegression( normalize=True, fit_intercept = True )\n",
    "#cv = number of folds\n",
    "cross = cross_val_score(clf, X_train_degree2, y_train, cv=3, scoring = 'neg_root_mean_squared_error')\n",
    "cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df = metric_df.append(\n",
    "    {\n",
    "    'model': 'pol_dg2',\n",
    "    'rmse_train': pol_dg2['rmse'],    \n",
    "    'r^2' : pol_dg2['r2']}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>rmse_train</th>\n",
       "      <th>r^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline(using last year sales)</td>\n",
       "      <td>91145.282235</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ols_rfe</td>\n",
       "      <td>71859.757450</td>\n",
       "      <td>0.983443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lasso_rfe</td>\n",
       "      <td>72080.269213</td>\n",
       "      <td>0.983309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gml_rfe</td>\n",
       "      <td>71522.664037</td>\n",
       "      <td>0.983598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pol3_skb</td>\n",
       "      <td>64044.020372</td>\n",
       "      <td>0.986849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pol3_rfe</td>\n",
       "      <td>60488.511133</td>\n",
       "      <td>0.988269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pol_dg2</td>\n",
       "      <td>69757.437550</td>\n",
       "      <td>0.984398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             model    rmse_train       r^2\n",
       "0  baseline(using last year sales)  91145.282235  0.000000\n",
       "1                          ols_rfe  71859.757450  0.983443\n",
       "2                        lasso_rfe  72080.269213  0.983309\n",
       "3                          gml_rfe  71522.664037  0.983598\n",
       "4                         pol3_skb  64044.020372  0.986849\n",
       "5                         pol3_rfe  60488.511133  0.988269\n",
       "6                          pol_dg2  69757.437550  0.984398"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use my function to create and calculate the metrics\n",
    "pol_reg_test =  create_model(X_test_degree3, \n",
    "                              y_test_df, 'actual',LinearRegression( normalize=False, fit_intercept = True ), 'test_polreg' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62577.99078326525"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pol_reg_test['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
